https://scielo.conicyt.cl/scielo.php?script=sci_arttext&pid=S0034-98872018000100046
Análisis de pruebas escritas bajo los principios de la evaluación auténtica. Estudio comparativo entre carreras de la salud y otras carreras de dos universidades de la Región del Biobío

La evaluación del aprendizaje tiene gran impacto en la calidad de lo aprendido1,2. Impulsa y modela los tipos de aprendizajes que se quieren lograr y consolida el uso de ciertas habilidades cognitivas3, junto con su calidad y profundidad4–6. Además, permite a los profesores saber cómo los estudiantes están aprendiendo, apreciar la calidad de su desempeño y tomar decisiones pedagógicas respecto a cómo se seguirá avanzando en el proceso de enseñanza7.

En la educación chilena, la evaluación del aprendizaje es el área más deficitaria de la práctica pedagógica8. En educación superior se ha avanzado, especialmente, en las carreras del área de la salud, a través de tareas de desempeño como portafolios, aprendizaje basado en problemas (ABP), simulaciones o evaluación clínica objetiva estructurada (ECOE)9,10. Sin embargo, en general, la apertura de los docentes para hacer cambios en su sistema de evaluación se ha concentrado en la medición de procedimientos o habilidades11. Los docentes muestran resistencias para cambiar la evaluación formal a través de pruebas y exámenes escritos, sosteniendo la creencia de que aprender involucra la reproducción literal del saber, la acumulación de datos, conceptos y habilidades básicas. Esta forma de evaluar lo aprendido influencia a los estudiantes en adoptar un enfoque superficial de aprendizaje en comparación a un enfoque profundo12,13.

Hace más de 20 años, el paradigma de la evaluación avanzó desde los tests objetivos y estandarizados, que se focalizaban en medir porciones de conocimiento atomizado, hacia una evaluación más compleja y amplia de conocimiento y habilidades de orden14,15. Desde esta mirada, la evaluación, la enseñanza y el aprendizaje están íntimamente relacionados. Una buena evaluación debe estar diseñada de tal forma que los estudiantes, al rendirla, aprendan y se comprometan con su proceso educativo, permitiéndoles aplicar lo aprendido para resolver algún problema16.

La evaluación auténtica forma parte de este cambio de paradigma. Busca acercar lo que sucede en las aulas a la vida real, replicando las tareas y estándares de desempeño que típicamente enfrentan los profesionales en el mundo del trabajo17. Enfrenta a los estudiantes con problemas que simulan contextos realistas y problematizadores, midiendo habilidades cognitivas de orden superior18.

La literatura señala, además, que la evaluación auténtica tiene un impacto en la autonomía del estudiante19, su compromiso y motivación con el proceso de aprender20, capacidad de autorregulación, metacognición y autorreflexión21. Es una metodología pertinente de utilizar en educación superior y que se convierte en una oportunidad para vincular la academia con el mundo del trabajo.

Bajo este modelo, el diseño de una evaluación escrita debe contemplar dos condiciones. Por un lado, medir el aprendizaje de manera contextualizada, a través de estímulos realistas y situados, comprometiendo a los estudiantes con problemas o preguntas importantes, que vale la pena responder más allá del interés pedagógico de las aulas22. Por otro lado, debe presentar un nivel de complejidad cognitiva que demande al estudiante a construir conocimiento, haciendo uso de habilidades cognitivas complejas23. Se ha comprobado que, cuando los estudiantes hacen uso de este tipo de habilidades, logran mayor profundidad en la comprensión del contenido4 y estabilidad en el recuerdo de lo aprendido24.

En este artículo se presenta un estudio en 6 carreras de dos universidades de la Región del Biobío (fonoaudiología, tecnología médica y enfermería, del área de salud e ingeniería comercial, psicología y bioingeniería, de otras áreas). Se realizó un análisis de los ítems de pruebas escritas aplicadas a estudiantes de tercer y cuarto año de carrera, respecto al cumplimiento de los principios de la metodología de evaluación auténtica. Este análisis se hizo antes y después de una intervención, en la que se capacitó a los docentes en la metodología de evaluación auténtica. De esta forma, se compararon los resultados de las carreras de la salud y las de otras áreas, a nivel de pre y posttest. El objetivo del trabajo es describir la realidad de la construcción de pruebas escritas y relevar la necesidad de evaluar los aprendizajes de manera contextualizada, con problemas cercanos a la realidad profesional, que midan habilidades cognitivas de orden superior, dando cuenta de la complejidad cognitiva que requiere la resolución de problemas vinculada al ámbito profesional.

Se intencionó evaluar cómo se construyen las pruebas en carreras de salud, comparando con otro tipo de programas, dado que, generalmente, estas presentan ventajas respecto a la calidad y “autenticidad” de su proceso formativo. Se caracterizan por tener unidades de educación médica, en las que capacitan a sus profesores en temas de docencia universitaria, y utilizan actividades prácticas en contextos auténticos, como simulaciones y observaciones.

Material y Método

Diseño de investigación

La metodología fue cuantitativa, con un alcance descriptivo y correlacional. El diseño corresponde a un estudio longitudinal de medidas repetidas25. El muestreo fue intencionado. El tamaño muestral fue de 2.369 ítems (1.318 en el pretest y 1.051 en el posttest). Estos se encontraban distribuidos en 181 pruebas (88 en el pretest y 93 en el posttest). La carrera que entregó más evaluaciones contaba con 708 ítems y 41 pruebas, y la que entregó menos presentaba 203 ítems y 12 pruebas. El promedio de ítems por carrera fue de 394.83 y el promedio de pruebas por carrera fue de 3.017.

Instrumentos

Se trabajó con una escala de apreciación que medía indicadores de la evaluación auténtica, la cual se construyó posterior a un estudio del estado del arte del constructo. Esta escala fue evaluada por 5 jueces expertos, siendo el acuerdo interjueces de 92%. Se hizo un estudio piloto para analizar la concordancia entre 2 evaluadores al tabular los ítems de 30 pruebas. El coeficiente de Kappa de Cohen obtuvo un valor de 0,82, mostrando alto acuerdo. Se valoró cada ítem en los siguientes 4 aspectos, utilizando una escala que iba de 1 a 3 puntos, en la que 1 implicaba un nivel bajo, 2 uno medio y 3 uno alto:

1. Complejidad cognitiva

Se clasificó cada ítem en el nivel de habilidad cognitiva que se debe hacer uso para dar respuesta a la pregunta. Los niveles son tres: reconocimiento de información (nivel memorístico: 1 y 2 de Bloom26), manejo de información (nivel analítico: 3 y 4 de Bloom26) y transferencia de información (nivel decisional: 5 y 6 de Bloom26).

2. Realismo

Evaluó la contextualización, problematización y realismo presente en la pregunta, es decir, si lo que se preguntaba estaba relacionado con una situación-problema de la vida real o profesional, en que se debía aplicar el contenido curricular para responder.

3. Alineación con competencias específicas del perfil de egreso

Se analizó la relación de lo medido con las competencias específicas (propias de la profesión) declaradas en el perfil de egreso de cada carrera.

4. Alineación con competencias genéricas del perfil de egreso

Se analizó la relación de lo medido en cada ítem de la prueba con las competencias genéricas (transversales a distintas profesiones) declaradas en el perfil de egreso de cada carrera. Se decidió trabajar con estos indicadores debido a que la revisión de la literatura evidenció que son las cuatro dimensiones más representativas del Modelo de Evaluación Auténtica.

Procedimiento

Se invitó a participar a las carreras (3 de cada universidad), todas con una duración de 5 años, solicitándoles las pruebas escritas de los dos últimos años de calendario, en los niveles de 3er y 4to año de cada carrera, de 19 profesores (4 de psicología, 3 de ingeniería comercial, 3 de bioingeniería, 2 de enfermería, 4 de tecnología médica y 3 de fonoaudiología). También se pidió el perfil de egreso de cada programa. Luego, los docentes fueron capacitados durante un semestre (en 2014), en la metodología de evaluación auténtica y aplicaron lo aprendido durante el siguiente semestre académico27. Luego de implementada la metodología, los docentes entregaron las pruebas aplicadas a los estudiantes ese semestre post intervención (mediados de 2015). Las pruebas aplicadas fueron sumativas y de proceso. Correspondían a certámenes y exámenes.

Para asegurar la calidad técnica de los ítems y las pruebas, junto con su relación con los objetivos de los cursos, se tomaron algunos resguardos. Los profesores que participaron en la investigación, y fueron capacitados, fueron sugeridos por los directores de carrera de cada universidad, considerando a docentes que se destacaban en su ejercicio profesional, por su compromiso, experiencia y evaluación docente. Además, las pruebas, construidas a partir de la capacitación, fueron visadas por cada carrera (equipos docentes internos de cada carrera, que se encargan de procesos académicos y curriculares) respecto al cumplimiento con los contenidos del curso y los resultados de aprendizaje del programa de asignatura que cada profesor dictaba. Finalmente, al construir la prueba, el profesor completaba una lista de chequeo que solicitaba alinear los ítems con los contenidos del curso y los resultados de aprendizaje que la asignatura comprometía, como también la redacción de la pregunta.

Plan de análisis de datos

El análisis de datos se efectuó mediante dos procesos. El primero consistió en examinar el tipo de ítems utilizados en las pruebas antes y después de la capacitación, en las carreras de la salud y las carreras de otras áreas. Además, se comparó el cambio en el tipo de ítems, según el área disciplinar de las carreras (salud y otras). Para esto se utilizaron porcentajes.

En el segundo proceso se evaluó el nivel de presencia de los indicadores del Modelo de Evaluación Auténtica en las pruebas antes y después de la capacitación, en las mismas carreras. De igual manera se comparó el cambio según área disciplinar. Para este fin se utilizaron las medias.

Para modelar el cambio en los ítems, en ambos procesos, se empleó como técnica de análisis de datos el Modelo Jerárquico Lineal, HLM28, anidando los ítems a nivel de la prueba y del profesor.

Aspectos éticos

El Comité de Ética de Investigación Institucional de la Universidad del Desarrollo realizó una revisión del proyecto de investigación, aprobando su ejecución. Posteriormente, se solicitó permiso a las autoridades de todos los programas de pregrado que conformaron la muestra. Finalmente, se invitó a participar a los docentes, quienes fueron informados de la investigación y sus objetivos a través de un consentimiento informado. Su firma implicaba que aceptaban entregar sus pruebas, antes y después de la intervención, para ser analizadas. En este también se explicitaba el carácter voluntario de la participación y se aseguraba el resguardo del anonimato de los datos.

Resultados

Los resultados evidencian que antes de la capacitación, los ítems más utilizados, por ambos tipos de carrera, eran de selección múltiple, seguidos por verdadero y falso, desarrollo breve y análisis de casos, en las carreras de la salud. En las otras carreras (ingeniería comercial, psicología y bioingeniería), los más utilizados fueron análisis de caso, desarrollo breve y desarrollo extenso. Si se agrupa los ítems en preguntas de respuesta abierta y cerrada, las carreras de la salud superaban a las carreras de otras áreas en ítems de respuesta cerrada, mientras que las demás carreras destacaban en su nivel de preguntas de respuesta abierta (Tabla 1).

Tabla 1 Porcentaje de tipos de ítems utilizados en las pruebas, según área disciplinar de las carreras 

aítems de respuesta abierta;

bítems de respuesta cerrada;

cValor-p alude a la significancia del cambio logrado en ambos grupos de carreras;

*Valor-p significativo.

Posterior a la intervención, en las carreras de la salud se utilizó más análisis de caso, seguido por desarrollo breve, selección múltiple, y verdadero o falso, mientras que en las demás, se usó más selección múltiple, seguido por desarrollo breve, análisis de caso y desarrollo extenso. También se observó un cambio relevante en los ítems en preguntas de respuesta abierta y cerrada, tras la intervención. Las carreras de la salud disminuyeron a la mitad sus ítems de respuesta cerrada y aumentan al doble los de respuesta abierta, logrando que no existieran diferencias significativas entre ambos tipos de ítems con las otras carreras.

Por otro lado, el análisis realizado con HLM mostró que existían cambios dependientes del tipo de carrera en todos los ítems, a excepción de los de resolución breve de problemas y de desarrollo extenso. En análisis de caso, se observa que las carreras de salud aumentaron en más de 16%, siendo este aumento mucho mayor que el de las demás carreras. Lo mismo ocurrió con la utilización de desarrollo breve. Su uso aumentó de mayor manera en las otras carreras. Si bien, se disminuyó el uso de selección múltiple, esta baja fue mucho mayor en las carreras de otras áreas. Algo similar ocurrió con los verdadero o falso y la completación, los cuales disminuyeron, pero en las demás carreras no se utilizaron más (Tabla 2).

Tabla 2 Indicadores de Evaluación Auténtica medidos en las pruebas, según área disciplinar de la carrera 

cValor-p alude a la significancia del cambio logrado en ambos grupos de carreras;

*Valor-p significativo.

Antes de la capacitación se observaba que todos los indicadores se encontraban cercanos al puntaje medio, a excepción de la alineación con las competencias genéricas del perfil de egreso, que fue el indicador con una media más baja. Posterior a la intervención se evidenció que todos los indicadores aumentaron sus puntajes. Sin embargo, la alineación de los ítems con las competencias genéricas sigue siendo el más bajo, para ambos tipos de carreras.

El análisis con HLM mostró que existieron cambios dependientes del tipo de carrera en todos los indicadores. Todas las carreras aumentaron sus puntajes posterior a la intervención. Sin embargo, el aumento fue mayor en las carreras de la salud, en los indicadores de complejidad cognitiva, realismo y alineación con las competencias específicas, mientras que el aumento fue mayor para las carreras de otras áreas en el indicador de alineación con las competencias genéricas.

Discusión

Las carreras de la salud tienen gran experiencia a la hora de evaluar competencias, habilidades o procedimientos, a través de tareas de desempeño como son las simulaciones, ECOE u observaciones. No obstante, la construcción de pruebas escritas, que representan la forma de evaluar el contenido curricular, presenta importantes oportunidades de mejora, al compararla con carreras de otras áreas disciplinares. Antes de la intervención, las pruebas presentan un alto número de ítems de respuesta cerrada, descontextualizados y de baja complejidad cognitiva. Esta forma de preguntar acerca del conocimiento, tiende a favorecer un aprendizaje superficial y memorístico en los estudiantes, dificultando la aplicación del saber. Las pruebas escritas carecen de autenticidad, estando desvinculadas con los problemas que se enfrentan en el mundo del trabajo. A pesar de ello, la fortaleza de las carreras de la salud es que sus profesores están abiertos a aprender rápidamente y son capaces de generar cambios en la construcción de pruebas escritas, al ser capacitados para ello. Una vez realizado el entrenamiento docente en la metodología de evaluación auténtica, las pruebas escritas cambiaron significativamente, aumentando el número de ítems de respuesta abierta, disminuyendo las preguntas de respuesta cerrada, aumentando la complejidad cognitiva y realismo de los ítems, como también su nivel de alineación con las competencias específicas del perfil de egreso de cada carrera. De esta forma, lograron equipararse a los índices de las carreras de otras áreas, e incluso superarlos, por ejemplo, en el realismo y contextualización de los ítems.