https://scielo.conicyt.cl/scielo.php?script=sci_arttext&pid=S0370-41061999000400009
Tamaño muestral en estudios biomédicos

  INTRODUCCIÓN  

Establecer el tamaño muestral apropiado para una investigación    es a la vez frecuentemente complicado y representa sólo una aproximación    a la realidad, sin embargo es muy necesario. Fallas en detectar diferencias    entre tratamientos con bastante frecuencia se relacionan con un tamaño    inadecuado del estudio. Se suele advertir sobre el riesgo de efectuar estudios    con muestras muy grandes, donde puede ocurrir que pequeñas diferencias,    probablemente sin trascendencia clínica, serán detectadas como    significativas1. Este no es el problema que enfrenta    el clínico, quien habitualmente tiene dificultades para reunir una muestra    del tamaño necesario para detectar una diferencia definida como "clínicamente    significativa". 

 Aun cuando los cálculos proporcionan datos aproximados, estos son importantes    porque permiten tener una idea de cuántos sujetos deberían participar    en el estudio y si sólo se dispone de un número fijo de estos,    nos puede indicar si realmente vale la pena emprender la investigación.  

 Dentro de varias cuestiones que podrán ser investigadas en un estudio,    seguramente será posible definir la principal. Entonces, se establecerá    qué clase de datos deben ser obtenidos y la forma como serán analizados.    Esto tiene mucha importancia, puesto que el tamaño de la muestra depende    del método de análisis a emplear. 

 La presente revisión introduce al problema planteado, con el fin de    mostrar en términos generales los escenarios y soluciones más    comúnmente empleados en investigación biomédica. 

  ELEMENTOS EN LA ESTIMACIÓN DEL TAMAÑO MUESTRAL  

Un conjunto de variables deberán ser consideradas en esta estimación:  

a)  Error alfa: 

 Corresponde, según la definición usual a "la probabilidad de    rechazar la hipótesis nula cuando esta es verdadera"2.    El investigador deberá establecer hasta qué punto estará    dispuesto a aceptar que los hallazgos de interés pudieran ser justificados    por variaciones explicables por el azar. Convencionalmente, se considera en    estudios clínicos un error alfa aceptable de 5% o menor, aunque más    precisamente inferior a 5%. Ello significa que si bien los resultados pudieran    ser explicados por el azar en 5 o menos de cada 100 veces que se repitiera la    experiencia, se decidirá interpretarlos, en tales circunstancias, como    no atribuibles al azar, es decir, "significativos". La elección de un    error alfa más pequeño (por ejemplo 1%) proporciona mayor probabilidad    que los resultados de interés correspondan a una situación real.    Sin embargo, aumenta el riesgo de atribuir al azar hallazgos que no debieran    ser interpretados de tal modo (puesto que sólo sería "significativo"    un valor de "p" igual o menor a 0,01 (1%)). 

 En los cálculos se emplea el valor "Z de alfa" (Za) que corresponde    en la curva normal estandarizada al número de desviaciones estándar    que aplicadas en ambos lados del promedio cero dejan fuera un área de    5% (correspondiente al error alfa elegido) (en cada cola queda entonces 2,5%).    Za para alfa 5% (0,05) en prueba bilateral es igual a 1,96 y para prueba unilateral    es 1,643. 

b)  Error beta 

Este error corresponde a la probabilidad de no detectar un hallazgo como importante    y atribuirlo al azar. Habitualmente se le define como "la probabilidad de no    rechazar la hipótesis nula cuando esta es falsa"2.    En estudios clínicos se considera apropiado un nivel de error beta de    20%. Naturalmente, se puede utilizar un nivel menor. Como sea, el poder del    estudio, es decir la probabilidad de rechazar la hipótesis nula cuando    es falsa, es igual a 100 menos el error beta. Esto significa que habitualmente    se trabaja con un poder de 80%. 

 Es importante destacar que la reducción del error beta invariablemente    va acompañada de aumento del error alfa, para un mismo tamaño    muestral. Una reducción de ambos errores sólo es posible aumentando    el tamaño de la muestra. Así, la muestra por grupo para detectar    una diferencia de 15% entre los valores de 20% y 35% con error alfa de 5% y    beta de 20% es de 151 casos; si bajamos el error beta a 10% y lo demás    no varía, se necesitan 198 casos por grupo; si sólo rebajamos    el error alfa a 1% los casos deben ser 219, y si simultáneamente deseamos    dejar los errores en 10% y 1%, respectivamente, se requerirán 275 casos    por grupo4,5. 

 En los cálculos se emplea el valor "Z de beta" (Zß) que corresponde    al número de desviaciones estándar de la curva normal estandarizada    que deja fuera, unilateralmente, un área igual al error beta escogido,    20% si empleamos poder de 80%. Zß en este caso es igual a 0,84 y si el    error beta es 10% (0,10) el valor es 1,28. 

c)  Diferencia clínicamente significativa 

Aquí se puede suponer una comparación entre dos grupos en un    ensayo clínico, donde se espera poder detectar una diferencia en los    resultados. Esta diferencia no es cualquiera, sino una igual o mayor a cierto    nivel que desde un punto de vista clínico sea de relevancia. Es así    como si un grupo tiene una proporción de complicaciones de 30% y se espera    una reducción con un tratamiento nuevo, con seguridad no se considerará    un cambio significativo el descenso a 28%. Por otra parte, si esa diferencia    es real, para detectarla se requeriría el estudio de un número    muy grande de casos. Es frecuente que una diferencia de interés sea catalogada    como superior a 10% y comúnmente alrededor de 15%. 

Un criterio similar se utiliza para elegir detectar razón de ventaja    (OR), riesgo relativo (RR) o razón de verosimilitud (LR). Es importante    tener presente que una misma diferencia inducirá a tamaños de    muestra variables de acuerdo con los valores entre los que tal diferencia se    establece. Así, 15% no opera igual si es entre 20% y 35% o entre 45%    y 60%, por lo que no basta con plantear en qué magnitud serán    diferentes los resultados. Si no se dispone de más información    respecto a este asunto, la solución es ensayar diferentes cálculos    y utilizar el tamaño muestral que resulte mayor. Si la falta de información    no es solucionable con relativa facilidad, se puede efectuar un estudio piloto    para obtener una aproximación. En tales circunstancias se recurriría    a los intervalos de confianza de los estadígrafos de interés para    obtener tamaño mínimo y máximo probable requerido para    el estudio. Más adelante volveremos sobre esto. 

 Mucho interés tiene la orientación que se requiere al pretender    verificar "igualdad de resultados". Esta situación podría corresponder    a la comparación de un tratamiento ya aceptado con otro que tiene varias    ventajas (requiere menos dosis al día, es menos costoso, etc.), aunque    se supone que genera resultados iguales. Si se establece "cero" como diferencia    a detectar, el tamaño de la muestra ascendería a infinito, por    ello es necesario plantear la detección de la diferencia más grande    que no sea clínicamente significativa. Así, si se plantea que    cualquier diferencia igual o menor a 6% se considerará como sin importancia,    el estudio será diseñado como capaz de pesquisar esta última    cifra. Entonces, si ambos tratamientos aparecen como comparables (p > 0,05),    se podrá pensar que o son iguales o difieren en una cuantía igual    o menor que 6%, lo que ya fue declarado como sin importancia clínica.  

d)  Hipótesis uni o bilateral 

 Un aspecto muy importante a considerar es si el tamaño de la muestra    se está estimando para la verificación de una hipótesis    uni o bilateral. Esto se refiere a que si al comparar dos grupos la hipótesis    es que los resultados diferirán sin poder predecir de seguro cuál    grupo resulta mejor o más favorable (bilateral, porque A puede ser mejor    que B o viceversa), o definitivamente se postula que, específicamente,    uno de los grupos dará mejores resultados. El problema planteado corresponde    a lo siguiente: si se realiza un ensayo clínico controlado para probar    un nuevo tratamiento, comparándolo con aquel generalmente aceptado, sólo    es éticamente aceptable que el investigador, aunque tenga sus esperanzas    puestas en que el nuevo tratamiento es mejor, no sabe si ello es así    y por tanto la hipótesis debe contemplar la posibilidad que el nuevo    tratamiento resulte comparable o aun inferior al generalmente utilizado. Se    entiende que si el investigador está razonablemente convencido que el    nuevo tratamiento es mejor, simplemente no puede someter al grupo control a    una terapia que considera inferior, menos efectiva. 

 Puesto que una prueba de hipótesis bilateral es más exigente    que una unilateral, podría alguien a posteriori y en vista de un resultado    insuficiente para una prueba bilateral, pero suficiente para una unilateral,    verse tentado a cambiar la hipótesis, sin embargo esto no es aceptable.  

 ¿En que casos sería razonable utilizar hipótesis unilaterales?    En algunas situaciones, algo distintas de la comentada, parece apropiado hacerlo.    Por ejemplo en un estudio de balance donde se compara dos grupos de niños,    en que el mayor aporte de líquidos a un grupo se espera tenga como efecto    un aumento del volumen de orina, si ello no se verifica, se interpretará    como retención6. 

 Otro elemento importante de tener presente es la posible pérdida de    casos dentro del estudio: no siguieron las indicaciones, se cambiaron a domicilio    desconocido, u otra causa. Como sea, sin mayores consideraciones, se debería    hacer una estimación por adelantado para corregir el tamaño de    la muestra. Así, en caso de esperar 10% de pérdida, el ajuste    implicaría multiplicar el tamaño de la muestra por el factor 100%/90%    = 1,11. Tal corrección no resuelve todo el problema, pues es importante    recordar que quienes abandonan un estudio o por alguna razón no se incorporan    a él, se deben considerar distintos de aquellos que sí lo hicieron.    De este modo no es indiferente tal acontecimiento, particularmente en el caso    de abandono de un estudio, ya que si la pérdida es muy numerosa puede    invalidar la investigación. Como no hay un criterio uniforme para decidir    cuánta pérdida debe ser considerada "grande", se puede hacer lo    siguiente: si en el estudio clínico apareciera una diferencia significativa    entre los grupos investigados, sólo se podrá considerar como una    conclusión válida si los casos perdidos en el seguimiento son    asignados al peor resultado y aún así se mantiene la diferencia    de interés. 

 El ejercicio de estimar el tamaño muestral aparentemente necesario    en diferentes estudios, confiere al investigador un saludable grado de cautela    cuando lee artículos que le interesan y, además, arroja luz sobre    los posibles efectos o consecuencias esperables en investigaciones fundadas    en muestras escasas. Estos incluyen: insuficiente poder y por ello una baja    probabilidad de detectar una diferencia planteada si existe, al disminuir el    tamaño del estudio se reduce la efectividad de la aleatorización    de los integrantes de la muestra, y la posibilidad de análisis estratificado    se aleja, puesto que si los casos son pocos ya de entrada al estratificar el    efecto de muestra escasa se manifestará más intensamente. 

 No pocas personas, al iniciar un estudio prefieren no averiguar cuántos    casos deben estudiar para verificar lo que les interesa. Esto se debe, al menos    en parte, a que se han llevado anteriormente una desagradable sorpresa al hacerlo    –constatando que requieren bastantes más casos que los imaginados– y    probablemente también porque en el fondo parecen pensar que todo el proceso    es una real exageración. Tienen el aparente apoyo de la literatura que    estudian, puesto que un cálculo del tamaño muestral no está    habitualmente incluido en los artículos y por otro lado no son raras    las investigaciones que dan resultados significativos con muy pocos casos gracias    a que la diferencia encontrada experimentalmente fue grande o que en comparación    de promedios la dispersión de los valores en cada grupo fue muy pequeña.  

 Como veremos más adelante, no siempre se pueden satisfacer todos los    requisitos que hemos analizado hasta el momento. En ocasiones convendrá    recordar que a partir de la prueba de hipótesis que se utilizará    es posible un acercamiento al tamaño muestral particular. 

 Por último, mencionaremos una idea que a veces surge relativa a todo    este asunto y se refiere a qué conducta se puede adoptar si no se dispone    de ningún dato de los que requiere el cálculo del tamaño    muestral. Una posibilidad, como ya se ha mencionado, es efectuar un estudio    piloto, la otra es considerar que si no se tiene dato alguno sobre el problema    que se desea estudiar probablemente no se justifica iniciar una investigación    sobre cuyo tema no se tiene experiencia alguna4.  

 A continuación analizaremos diferentes escenarios donde el cálculo    del tamaño de la muestra se plantea. Naturalmente no se pretende cubrir    todas las situaciones pero sí probablemente las más comunes. 

  I. ESTUDIOS EN QUE SE INDAGARÁ SOBRE UNA PREVALENCIA  

 En estos se requiere conocer5 el tamaño    de la población, la precisión deseada (%), la prevalencia esperada,    el efecto del diseño y el error alfa. 

 En este caso se debe tener una idea aproximada de la prevalencia que se está    investigando, luego se debe establecer cuánto se aceptaría que    varíe (precisión), luego el nivel de confianza deseado para la    indagación y finalmente el efecto de diseño de la investigación.    Este es igual a 1 (no hay efecto de diseño) si se ha empleado un procedimiento    de muestreo aleatorio simple o bien sistemático y corresponde a un error    sistemático. 

 La fórmula:            N  Z2  p (1-p)      n =          d2  (N-1) + Z2         p (1-p)      en que n es el tamaño de la muestra, N la población total, Z    el valor de z para el nivel de confianza (1- alfa), p la proporción esperada    en la población y d la precisión absoluta. El tamaño de    la muestra es, en definitiva, igual a n por el efecto de diseño. El tamaño    de la población de la que se extraerá la muestra es habitualmente    desconocido, pero no es muy importante tener un conocimiento exacto, bastando    con una aproximación razonable. En un ejemplo veremos que esto es así:    Supongamos que estimamos una proporción (p) en la población    a estudiar de 7% y deseamos un tamaño muestral que permita, con una seguridad    de 95% (Z entonces de 1,96), una variación alrededor de 7% de hasta 3%.    Ello significa que si la proporción poblacional es de 7% esperamos, con    95% de confianza, obtener un valor entre 4% y 10%. Para estos requisitos si    la población es de 500 000 personas, la muestra requerida es de 278 casos,    si es de 10 000 personas 271 casos, si sólo son 5 000 personas 264 y    si son 1 000 personas, 218 casos.       Si no tenemos idea alguna acerca del valor de p aún es posible estimar    el tamaño muestral: en la fórmula, la expresión p (1-p)    tiene un valor creciente a medida que la proporción p se va acercando    a 0,50, alcanza su máximo en ese punto y luego va descendiendo nuevamente.    Entonces, cuando p = 0,50 la mencionada expresión vale 0,25 y con esa    cifra se calculará en la fórmula el tamaño muestral, que    será el más elevado para las condiciones establecidas. Ese tamaño    de muestra será, entonces, el apropiado.       Estos cálculos se pueden realizar en el programa Epitable de EpiInfo.       II. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES  Se requiere en estos saber4 la razón grupo    1/ grupo 2, proporción en grupo 1, proporción en grupo 2, error    alfa y error beta.   La fórmula:  N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2     N´ =          r (p2 - p1)2    en que N es uno de los tamaños muestrales y Nr el otro, r es la fracción    que representa la muestra más pequeña respecto a la mayor, p1    la proporción del grupo 1, q1 = 1 - p1, p2 la proporción del grupo    2, q2 = 1 - p2, Za para hipótesis unilateral    1,645 (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es –0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10) y    – 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1- p.  De acuerdo con otros7, se puede obtener la información    por la siguiente vía para grupos de igual tamaño:  N = ( (Za + Zß) / (p1 - p2) )2    (p1 q1 + p2 q2)  donde N es el número de casos por grupo, p1 la proporción en    grupo 1, p2 la proporción en grupo 2, q1 = (1- p1) y q2 = (1 - p2).       Para una diferencia determinada, el tamaño muestral requerido no es    constante y depende de las proporciones entre las cuales se establece la diferencia.    Así, podemos ver al mismo tiempo que los resultados también dependen    del programa empleado, suponiendo que dejamos fijo el error alfa en 0,05 y el    error beta en 0,20 (tabla 1). Las cifras continúan    reduciéndose en espejo luego de haber ascendido a un máximo.      El programa Epilnfo emplea la fórmula de Fleiss4    y el Win Episcope 1,0 declara la de Snedecor y Cochran7.       En la eventualidad de poder establecer sólo la diferencia que interesa    detectar entre proporciones o porcentajes y los errores respectivos, la elección    de la muestra deberá corresponder, entonces, a la cifra mayor como ya    señaláramos anteriormente.       Tabla 1       Tamaño muestral para una diferencia de 0,15            entre dos proporciones según valores            de estas y programa estadístico utilizado, dado error alfa de            0,05 y beta de 0,20         Proporciones  Diferencia   Casos necesarios por grupo según programa                          Epilnfo 6.04     Win Episcope 1.08                      0,05 y 0,20            0,10 y 0,25            0,15 y 0,30            0,20 y 0,35            0,25 y 0,40            0,30 y 0,45            0,35 y 0,50            0,40 y 0,55            0,45 y 0,60            0,50 y 0,65            0,55 y 0,70                        0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15                        88            113            134            151            165            176            183            186            186            183            176                        74            98            119            137            151            161            168            172            172            168            161                       III. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES POR PRUEBA DE    FISHER-IRWIN DE PROBABILIDADES EXACTAS    En ocasiones, se puede presumir que en la investigación se incluirá    una muestra pequeña y se compararán dos grupos por la mencionada    prueba de hipótesis9.   Se dispone de tablas que proporcionan el tamaño muestral por grupo    requerido para satisfacer los errores alfa y beta planteados frente a la comparación    de dos proporciones10. A modo de ejemplo señalaremos    los datos que se proporcionan en la tabla 2.   El cálculo del tamaño muestral para estudiar la diferencia entre    dos proporciones en tabla de 2 x 2, con hipótesis unilateral, incluye    las dos proporciones y los errores alfa y beta. Debe contemplarse una proporción    como "control" o valor "patrón" (pl) y la otra sería "experimental"    (p2). En tales condiciones:      N = 1.641,6    [   (Za        + Zß)               (arcsen Rc p1 - arcsen Rc p2)  ]   2    donde Za es 1,64 si alfa es 0,05 para prueba unilateral    y 1,96 si es bilateral, Zß es 0,84 si beta es 0,20 para prueba uni o bilateral,    arcsen Rc p1 es el arcsen (corresponde "al ángulo cuyo seno es el valor    dado") de la raíz cuadrada (Rc) de la proporción 1.   Tabla 2      Tamaño muestral necesario por grupo, según            proporciones que se comparan            (p1, p2), para hipótesis unilateral, dado error alfa de 0,05            y beta de 0,20*         p2  p1               0,80      0,70      0,60      0,50      0,40      0,30      0,20           0,60 73               0,50 36 84             0,40  23 41 85           0,30 15 23 42 84         0,20 10 15 23 36 73       0,10 8 10 13 19 30 56 67   0,05 6 9 11 14 20 34          * Modificado de referencia          10.          En su calculadora arcsen sería sen elevado a -    1.        La prueba de hipótesis que se supone se empleará    con los resultados del estudio es Ji2.       IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA  Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.    Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que        a/(a+c)      LR+ =           b/(b+d)       En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).    Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%.   La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12.  El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo.  Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:   N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2      N´ =        r (p2 - p1)2   siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

      N  Z2  p (1-p)      n =          d2  (N-1) + Z2         p (1-p)      en que n es el tamaño de la muestra, N la población total, Z    el valor de z para el nivel de confianza (1- alfa), p la proporción esperada    en la población y d la precisión absoluta. El tamaño de    la muestra es, en definitiva, igual a n por el efecto de diseño. El tamaño    de la población de la que se extraerá la muestra es habitualmente    desconocido, pero no es muy importante tener un conocimiento exacto, bastando    con una aproximación razonable. En un ejemplo veremos que esto es así:    Supongamos que estimamos una proporción (p) en la población    a estudiar de 7% y deseamos un tamaño muestral que permita, con una seguridad    de 95% (Z entonces de 1,96), una variación alrededor de 7% de hasta 3%.    Ello significa que si la proporción poblacional es de 7% esperamos, con    95% de confianza, obtener un valor entre 4% y 10%. Para estos requisitos si    la población es de 500 000 personas, la muestra requerida es de 278 casos,    si es de 10 000 personas 271 casos, si sólo son 5 000 personas 264 y    si son 1 000 personas, 218 casos.       Si no tenemos idea alguna acerca del valor de p aún es posible estimar    el tamaño muestral: en la fórmula, la expresión p (1-p)    tiene un valor creciente a medida que la proporción p se va acercando    a 0,50, alcanza su máximo en ese punto y luego va descendiendo nuevamente.    Entonces, cuando p = 0,50 la mencionada expresión vale 0,25 y con esa    cifra se calculará en la fórmula el tamaño muestral, que    será el más elevado para las condiciones establecidas. Ese tamaño    de muestra será, entonces, el apropiado.       Estos cálculos se pueden realizar en el programa Epitable de EpiInfo.       II. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES  Se requiere en estos saber4 la razón grupo    1/ grupo 2, proporción en grupo 1, proporción en grupo 2, error    alfa y error beta.   La fórmula:  N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2     N´ =          r (p2 - p1)2    en que N es uno de los tamaños muestrales y Nr el otro, r es la fracción    que representa la muestra más pequeña respecto a la mayor, p1    la proporción del grupo 1, q1 = 1 - p1, p2 la proporción del grupo    2, q2 = 1 - p2, Za para hipótesis unilateral    1,645 (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es –0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10) y    – 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1- p.  De acuerdo con otros7, se puede obtener la información    por la siguiente vía para grupos de igual tamaño:  N = ( (Za + Zß) / (p1 - p2) )2    (p1 q1 + p2 q2)  donde N es el número de casos por grupo, p1 la proporción en    grupo 1, p2 la proporción en grupo 2, q1 = (1- p1) y q2 = (1 - p2).       Para una diferencia determinada, el tamaño muestral requerido no es    constante y depende de las proporciones entre las cuales se establece la diferencia.    Así, podemos ver al mismo tiempo que los resultados también dependen    del programa empleado, suponiendo que dejamos fijo el error alfa en 0,05 y el    error beta en 0,20 (tabla 1). Las cifras continúan    reduciéndose en espejo luego de haber ascendido a un máximo.      El programa Epilnfo emplea la fórmula de Fleiss4    y el Win Episcope 1,0 declara la de Snedecor y Cochran7.       En la eventualidad de poder establecer sólo la diferencia que interesa    detectar entre proporciones o porcentajes y los errores respectivos, la elección    de la muestra deberá corresponder, entonces, a la cifra mayor como ya    señaláramos anteriormente.       Tabla 1       Tamaño muestral para una diferencia de 0,15            entre dos proporciones según valores            de estas y programa estadístico utilizado, dado error alfa de            0,05 y beta de 0,20         Proporciones  Diferencia   Casos necesarios por grupo según programa                          Epilnfo 6.04     Win Episcope 1.08                      0,05 y 0,20            0,10 y 0,25            0,15 y 0,30            0,20 y 0,35            0,25 y 0,40            0,30 y 0,45            0,35 y 0,50            0,40 y 0,55            0,45 y 0,60            0,50 y 0,65            0,55 y 0,70                        0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15                        88            113            134            151            165            176            183            186            186            183            176                        74            98            119            137            151            161            168            172            172            168            161                       III. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES POR PRUEBA DE    FISHER-IRWIN DE PROBABILIDADES EXACTAS    En ocasiones, se puede presumir que en la investigación se incluirá    una muestra pequeña y se compararán dos grupos por la mencionada    prueba de hipótesis9.   Se dispone de tablas que proporcionan el tamaño muestral por grupo    requerido para satisfacer los errores alfa y beta planteados frente a la comparación    de dos proporciones10. A modo de ejemplo señalaremos    los datos que se proporcionan en la tabla 2.   El cálculo del tamaño muestral para estudiar la diferencia entre    dos proporciones en tabla de 2 x 2, con hipótesis unilateral, incluye    las dos proporciones y los errores alfa y beta. Debe contemplarse una proporción    como "control" o valor "patrón" (pl) y la otra sería "experimental"    (p2). En tales condiciones:      N = 1.641,6    [   (Za        + Zß)               (arcsen Rc p1 - arcsen Rc p2)  ]   2    donde Za es 1,64 si alfa es 0,05 para prueba unilateral    y 1,96 si es bilateral, Zß es 0,84 si beta es 0,20 para prueba uni o bilateral,    arcsen Rc p1 es el arcsen (corresponde "al ángulo cuyo seno es el valor    dado") de la raíz cuadrada (Rc) de la proporción 1.   Tabla 2      Tamaño muestral necesario por grupo, según            proporciones que se comparan            (p1, p2), para hipótesis unilateral, dado error alfa de 0,05            y beta de 0,20*         p2  p1               0,80      0,70      0,60      0,50      0,40      0,30      0,20           0,60 73               0,50 36 84             0,40  23 41 85           0,30 15 23 42 84         0,20 10 15 23 36 73       0,10 8 10 13 19 30 56 67   0,05 6 9 11 14 20 34          * Modificado de referencia          10.          En su calculadora arcsen sería sen elevado a -    1.        La prueba de hipótesis que se supone se empleará    con los resultados del estudio es Ji2.       IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA  Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.    Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que        a/(a+c)      LR+ =           b/(b+d)       En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).    Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%.   La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12.  El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo.  Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:   N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2      N´ =        r (p2 - p1)2   siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 

en que n es el tamaño de la muestra, N la población total, Z    el valor de z para el nivel de confianza (1- alfa), p la proporción esperada    en la población y d la precisión absoluta. El tamaño de    la muestra es, en definitiva, igual a n por el efecto de diseño. El tamaño    de la población de la que se extraerá la muestra es habitualmente    desconocido, pero no es muy importante tener un conocimiento exacto, bastando    con una aproximación razonable. En un ejemplo veremos que esto es así:  

 Supongamos que estimamos una proporción (p) en la población    a estudiar de 7% y deseamos un tamaño muestral que permita, con una seguridad    de 95% (Z entonces de 1,96), una variación alrededor de 7% de hasta 3%.    Ello significa que si la proporción poblacional es de 7% esperamos, con    95% de confianza, obtener un valor entre 4% y 10%. Para estos requisitos si    la población es de 500 000 personas, la muestra requerida es de 278 casos,    si es de 10 000 personas 271 casos, si sólo son 5 000 personas 264 y    si son 1 000 personas, 218 casos.       Si no tenemos idea alguna acerca del valor de p aún es posible estimar    el tamaño muestral: en la fórmula, la expresión p (1-p)    tiene un valor creciente a medida que la proporción p se va acercando    a 0,50, alcanza su máximo en ese punto y luego va descendiendo nuevamente.    Entonces, cuando p = 0,50 la mencionada expresión vale 0,25 y con esa    cifra se calculará en la fórmula el tamaño muestral, que    será el más elevado para las condiciones establecidas. Ese tamaño    de muestra será, entonces, el apropiado.       Estos cálculos se pueden realizar en el programa Epitable de EpiInfo.       II. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES  Se requiere en estos saber4 la razón grupo    1/ grupo 2, proporción en grupo 1, proporción en grupo 2, error    alfa y error beta.   La fórmula:  N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2     N´ =          r (p2 - p1)2    en que N es uno de los tamaños muestrales y Nr el otro, r es la fracción    que representa la muestra más pequeña respecto a la mayor, p1    la proporción del grupo 1, q1 = 1 - p1, p2 la proporción del grupo    2, q2 = 1 - p2, Za para hipótesis unilateral    1,645 (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es –0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10) y    – 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1- p.  De acuerdo con otros7, se puede obtener la información    por la siguiente vía para grupos de igual tamaño:  N = ( (Za + Zß) / (p1 - p2) )2    (p1 q1 + p2 q2)  donde N es el número de casos por grupo, p1 la proporción en    grupo 1, p2 la proporción en grupo 2, q1 = (1- p1) y q2 = (1 - p2).       Para una diferencia determinada, el tamaño muestral requerido no es    constante y depende de las proporciones entre las cuales se establece la diferencia.    Así, podemos ver al mismo tiempo que los resultados también dependen    del programa empleado, suponiendo que dejamos fijo el error alfa en 0,05 y el    error beta en 0,20 (tabla 1). Las cifras continúan    reduciéndose en espejo luego de haber ascendido a un máximo.      El programa Epilnfo emplea la fórmula de Fleiss4    y el Win Episcope 1,0 declara la de Snedecor y Cochran7.       En la eventualidad de poder establecer sólo la diferencia que interesa    detectar entre proporciones o porcentajes y los errores respectivos, la elección    de la muestra deberá corresponder, entonces, a la cifra mayor como ya    señaláramos anteriormente.       Tabla 1       Tamaño muestral para una diferencia de 0,15            entre dos proporciones según valores            de estas y programa estadístico utilizado, dado error alfa de            0,05 y beta de 0,20         Proporciones  Diferencia   Casos necesarios por grupo según programa                          Epilnfo 6.04     Win Episcope 1.08                      0,05 y 0,20            0,10 y 0,25            0,15 y 0,30            0,20 y 0,35            0,25 y 0,40            0,30 y 0,45            0,35 y 0,50            0,40 y 0,55            0,45 y 0,60            0,50 y 0,65            0,55 y 0,70                        0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15                        88            113            134            151            165            176            183            186            186            183            176                        74            98            119            137            151            161            168            172            172            168            161                       III. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES POR PRUEBA DE    FISHER-IRWIN DE PROBABILIDADES EXACTAS    En ocasiones, se puede presumir que en la investigación se incluirá    una muestra pequeña y se compararán dos grupos por la mencionada    prueba de hipótesis9.   Se dispone de tablas que proporcionan el tamaño muestral por grupo    requerido para satisfacer los errores alfa y beta planteados frente a la comparación    de dos proporciones10. A modo de ejemplo señalaremos    los datos que se proporcionan en la tabla 2.   El cálculo del tamaño muestral para estudiar la diferencia entre    dos proporciones en tabla de 2 x 2, con hipótesis unilateral, incluye    las dos proporciones y los errores alfa y beta. Debe contemplarse una proporción    como "control" o valor "patrón" (pl) y la otra sería "experimental"    (p2). En tales condiciones:      N = 1.641,6    [   (Za        + Zß)               (arcsen Rc p1 - arcsen Rc p2)  ]   2    donde Za es 1,64 si alfa es 0,05 para prueba unilateral    y 1,96 si es bilateral, Zß es 0,84 si beta es 0,20 para prueba uni o bilateral,    arcsen Rc p1 es el arcsen (corresponde "al ángulo cuyo seno es el valor    dado") de la raíz cuadrada (Rc) de la proporción 1.   Tabla 2      Tamaño muestral necesario por grupo, según            proporciones que se comparan            (p1, p2), para hipótesis unilateral, dado error alfa de 0,05            y beta de 0,20*         p2  p1               0,80      0,70      0,60      0,50      0,40      0,30      0,20           0,60 73               0,50 36 84             0,40  23 41 85           0,30 15 23 42 84         0,20 10 15 23 36 73       0,10 8 10 13 19 30 56 67   0,05 6 9 11 14 20 34          * Modificado de referencia          10.          En su calculadora arcsen sería sen elevado a -    1.        La prueba de hipótesis que se supone se empleará    con los resultados del estudio es Ji2.       IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA  Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.    Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que        a/(a+c)      LR+ =           b/(b+d)       En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).    Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%.   La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12.  El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo.  Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:   N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2      N´ =        r (p2 - p1)2   siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 Si no tenemos idea alguna acerca del valor de p aún es posible estimar    el tamaño muestral: en la fórmula, la expresión p (1-p)    tiene un valor creciente a medida que la proporción p se va acercando    a 0,50, alcanza su máximo en ese punto y luego va descendiendo nuevamente.    Entonces, cuando p = 0,50 la mencionada expresión vale 0,25 y con esa    cifra se calculará en la fórmula el tamaño muestral, que    será el más elevado para las condiciones establecidas. Ese tamaño    de muestra será, entonces, el apropiado.       Estos cálculos se pueden realizar en el programa Epitable de EpiInfo.       II. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES  Se requiere en estos saber4 la razón grupo    1/ grupo 2, proporción en grupo 1, proporción en grupo 2, error    alfa y error beta.   La fórmula:  N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2     N´ =          r (p2 - p1)2    en que N es uno de los tamaños muestrales y Nr el otro, r es la fracción    que representa la muestra más pequeña respecto a la mayor, p1    la proporción del grupo 1, q1 = 1 - p1, p2 la proporción del grupo    2, q2 = 1 - p2, Za para hipótesis unilateral    1,645 (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es –0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10) y    – 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1- p.  De acuerdo con otros7, se puede obtener la información    por la siguiente vía para grupos de igual tamaño:  N = ( (Za + Zß) / (p1 - p2) )2    (p1 q1 + p2 q2)  donde N es el número de casos por grupo, p1 la proporción en    grupo 1, p2 la proporción en grupo 2, q1 = (1- p1) y q2 = (1 - p2).       Para una diferencia determinada, el tamaño muestral requerido no es    constante y depende de las proporciones entre las cuales se establece la diferencia.    Así, podemos ver al mismo tiempo que los resultados también dependen    del programa empleado, suponiendo que dejamos fijo el error alfa en 0,05 y el    error beta en 0,20 (tabla 1). Las cifras continúan    reduciéndose en espejo luego de haber ascendido a un máximo.      El programa Epilnfo emplea la fórmula de Fleiss4    y el Win Episcope 1,0 declara la de Snedecor y Cochran7.       En la eventualidad de poder establecer sólo la diferencia que interesa    detectar entre proporciones o porcentajes y los errores respectivos, la elección    de la muestra deberá corresponder, entonces, a la cifra mayor como ya    señaláramos anteriormente.       Tabla 1       Tamaño muestral para una diferencia de 0,15            entre dos proporciones según valores            de estas y programa estadístico utilizado, dado error alfa de            0,05 y beta de 0,20         Proporciones  Diferencia   Casos necesarios por grupo según programa                          Epilnfo 6.04     Win Episcope 1.08                      0,05 y 0,20            0,10 y 0,25            0,15 y 0,30            0,20 y 0,35            0,25 y 0,40            0,30 y 0,45            0,35 y 0,50            0,40 y 0,55            0,45 y 0,60            0,50 y 0,65            0,55 y 0,70                        0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15                        88            113            134            151            165            176            183            186            186            183            176                        74            98            119            137            151            161            168            172            172            168            161                       III. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES POR PRUEBA DE    FISHER-IRWIN DE PROBABILIDADES EXACTAS    En ocasiones, se puede presumir que en la investigación se incluirá    una muestra pequeña y se compararán dos grupos por la mencionada    prueba de hipótesis9.   Se dispone de tablas que proporcionan el tamaño muestral por grupo    requerido para satisfacer los errores alfa y beta planteados frente a la comparación    de dos proporciones10. A modo de ejemplo señalaremos    los datos que se proporcionan en la tabla 2.   El cálculo del tamaño muestral para estudiar la diferencia entre    dos proporciones en tabla de 2 x 2, con hipótesis unilateral, incluye    las dos proporciones y los errores alfa y beta. Debe contemplarse una proporción    como "control" o valor "patrón" (pl) y la otra sería "experimental"    (p2). En tales condiciones:      N = 1.641,6    [   (Za        + Zß)               (arcsen Rc p1 - arcsen Rc p2)  ]   2    donde Za es 1,64 si alfa es 0,05 para prueba unilateral    y 1,96 si es bilateral, Zß es 0,84 si beta es 0,20 para prueba uni o bilateral,    arcsen Rc p1 es el arcsen (corresponde "al ángulo cuyo seno es el valor    dado") de la raíz cuadrada (Rc) de la proporción 1.   Tabla 2      Tamaño muestral necesario por grupo, según            proporciones que se comparan            (p1, p2), para hipótesis unilateral, dado error alfa de 0,05            y beta de 0,20*         p2  p1               0,80      0,70      0,60      0,50      0,40      0,30      0,20           0,60 73               0,50 36 84             0,40  23 41 85           0,30 15 23 42 84         0,20 10 15 23 36 73       0,10 8 10 13 19 30 56 67   0,05 6 9 11 14 20 34          * Modificado de referencia          10.          En su calculadora arcsen sería sen elevado a -    1.        La prueba de hipótesis que se supone se empleará    con los resultados del estudio es Ji2.       IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA  Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.    Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que        a/(a+c)      LR+ =           b/(b+d)       En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).    Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%.   La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12.  El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo.  Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:   N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2      N´ =        r (p2 - p1)2   siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 Estos cálculos se pueden realizar en el programa Epitable de EpiInfo.       II. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES  Se requiere en estos saber4 la razón grupo    1/ grupo 2, proporción en grupo 1, proporción en grupo 2, error    alfa y error beta.   La fórmula:  N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2     N´ =          r (p2 - p1)2    en que N es uno de los tamaños muestrales y Nr el otro, r es la fracción    que representa la muestra más pequeña respecto a la mayor, p1    la proporción del grupo 1, q1 = 1 - p1, p2 la proporción del grupo    2, q2 = 1 - p2, Za para hipótesis unilateral    1,645 (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es –0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10) y    – 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1- p.  De acuerdo con otros7, se puede obtener la información    por la siguiente vía para grupos de igual tamaño:  N = ( (Za + Zß) / (p1 - p2) )2    (p1 q1 + p2 q2)  donde N es el número de casos por grupo, p1 la proporción en    grupo 1, p2 la proporción en grupo 2, q1 = (1- p1) y q2 = (1 - p2).       Para una diferencia determinada, el tamaño muestral requerido no es    constante y depende de las proporciones entre las cuales se establece la diferencia.    Así, podemos ver al mismo tiempo que los resultados también dependen    del programa empleado, suponiendo que dejamos fijo el error alfa en 0,05 y el    error beta en 0,20 (tabla 1). Las cifras continúan    reduciéndose en espejo luego de haber ascendido a un máximo.      El programa Epilnfo emplea la fórmula de Fleiss4    y el Win Episcope 1,0 declara la de Snedecor y Cochran7.       En la eventualidad de poder establecer sólo la diferencia que interesa    detectar entre proporciones o porcentajes y los errores respectivos, la elección    de la muestra deberá corresponder, entonces, a la cifra mayor como ya    señaláramos anteriormente.       Tabla 1       Tamaño muestral para una diferencia de 0,15            entre dos proporciones según valores            de estas y programa estadístico utilizado, dado error alfa de            0,05 y beta de 0,20         Proporciones  Diferencia   Casos necesarios por grupo según programa                          Epilnfo 6.04     Win Episcope 1.08                      0,05 y 0,20            0,10 y 0,25            0,15 y 0,30            0,20 y 0,35            0,25 y 0,40            0,30 y 0,45            0,35 y 0,50            0,40 y 0,55            0,45 y 0,60            0,50 y 0,65            0,55 y 0,70                        0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15                        88            113            134            151            165            176            183            186            186            183            176                        74            98            119            137            151            161            168            172            172            168            161                       III. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES POR PRUEBA DE    FISHER-IRWIN DE PROBABILIDADES EXACTAS    En ocasiones, se puede presumir que en la investigación se incluirá    una muestra pequeña y se compararán dos grupos por la mencionada    prueba de hipótesis9.   Se dispone de tablas que proporcionan el tamaño muestral por grupo    requerido para satisfacer los errores alfa y beta planteados frente a la comparación    de dos proporciones10. A modo de ejemplo señalaremos    los datos que se proporcionan en la tabla 2.   El cálculo del tamaño muestral para estudiar la diferencia entre    dos proporciones en tabla de 2 x 2, con hipótesis unilateral, incluye    las dos proporciones y los errores alfa y beta. Debe contemplarse una proporción    como "control" o valor "patrón" (pl) y la otra sería "experimental"    (p2). En tales condiciones:      N = 1.641,6    [   (Za        + Zß)               (arcsen Rc p1 - arcsen Rc p2)  ]   2    donde Za es 1,64 si alfa es 0,05 para prueba unilateral    y 1,96 si es bilateral, Zß es 0,84 si beta es 0,20 para prueba uni o bilateral,    arcsen Rc p1 es el arcsen (corresponde "al ángulo cuyo seno es el valor    dado") de la raíz cuadrada (Rc) de la proporción 1.   Tabla 2      Tamaño muestral necesario por grupo, según            proporciones que se comparan            (p1, p2), para hipótesis unilateral, dado error alfa de 0,05            y beta de 0,20*         p2  p1               0,80      0,70      0,60      0,50      0,40      0,30      0,20           0,60 73               0,50 36 84             0,40  23 41 85           0,30 15 23 42 84         0,20 10 15 23 36 73       0,10 8 10 13 19 30 56 67   0,05 6 9 11 14 20 34          * Modificado de referencia          10.          En su calculadora arcsen sería sen elevado a -    1.        La prueba de hipótesis que se supone se empleará    con los resultados del estudio es Ji2.       IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA  Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.    Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que        a/(a+c)      LR+ =           b/(b+d)       En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).    Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%.   La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12.  El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo.  Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:   N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2      N´ =        r (p2 - p1)2   siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 II. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES

 Se requiere en estos saber4 la razón grupo    1/ grupo 2, proporción en grupo 1, proporción en grupo 2, error    alfa y error beta. 

 La fórmula: 

N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2 

donde: 

en que N es uno de los tamaños muestrales y Nr el otro, r es la fracción    que representa la muestra más pequeña respecto a la mayor, p1    la proporción del grupo 1, q1 = 1 - p1, p2 la proporción del grupo    2, q2 = 1 - p2, Za para hipótesis unilateral    1,645 (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es –0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10) y    – 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1- p. 

De acuerdo con otros7, se puede obtener la información    por la siguiente vía para grupos de igual tamaño: 

N = ( (Za + Zß) / (p1 - p2) )2    (p1 q1 + p2 q2) 

donde N es el número de casos por grupo, p1 la proporción en    grupo 1, p2 la proporción en grupo 2, q1 = (1- p1) y q2 = (1 - p2).       Para una diferencia determinada, el tamaño muestral requerido no es    constante y depende de las proporciones entre las cuales se establece la diferencia.    Así, podemos ver al mismo tiempo que los resultados también dependen    del programa empleado, suponiendo que dejamos fijo el error alfa en 0,05 y el    error beta en 0,20 (tabla 1). Las cifras continúan    reduciéndose en espejo luego de haber ascendido a un máximo.      El programa Epilnfo emplea la fórmula de Fleiss4    y el Win Episcope 1,0 declara la de Snedecor y Cochran7.       En la eventualidad de poder establecer sólo la diferencia que interesa    detectar entre proporciones o porcentajes y los errores respectivos, la elección    de la muestra deberá corresponder, entonces, a la cifra mayor como ya    señaláramos anteriormente.       Tabla 1       Tamaño muestral para una diferencia de 0,15            entre dos proporciones según valores            de estas y programa estadístico utilizado, dado error alfa de            0,05 y beta de 0,20         Proporciones  Diferencia   Casos necesarios por grupo según programa                          Epilnfo 6.04     Win Episcope 1.08                      0,05 y 0,20            0,10 y 0,25            0,15 y 0,30            0,20 y 0,35            0,25 y 0,40            0,30 y 0,45            0,35 y 0,50            0,40 y 0,55            0,45 y 0,60            0,50 y 0,65            0,55 y 0,70                        0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15                        88            113            134            151            165            176            183            186            186            183            176                        74            98            119            137            151            161            168            172            172            168            161                       III. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES POR PRUEBA DE    FISHER-IRWIN DE PROBABILIDADES EXACTAS    En ocasiones, se puede presumir que en la investigación se incluirá    una muestra pequeña y se compararán dos grupos por la mencionada    prueba de hipótesis9.   Se dispone de tablas que proporcionan el tamaño muestral por grupo    requerido para satisfacer los errores alfa y beta planteados frente a la comparación    de dos proporciones10. A modo de ejemplo señalaremos    los datos que se proporcionan en la tabla 2.   El cálculo del tamaño muestral para estudiar la diferencia entre    dos proporciones en tabla de 2 x 2, con hipótesis unilateral, incluye    las dos proporciones y los errores alfa y beta. Debe contemplarse una proporción    como "control" o valor "patrón" (pl) y la otra sería "experimental"    (p2). En tales condiciones:      N = 1.641,6    [   (Za        + Zß)               (arcsen Rc p1 - arcsen Rc p2)  ]   2    donde Za es 1,64 si alfa es 0,05 para prueba unilateral    y 1,96 si es bilateral, Zß es 0,84 si beta es 0,20 para prueba uni o bilateral,    arcsen Rc p1 es el arcsen (corresponde "al ángulo cuyo seno es el valor    dado") de la raíz cuadrada (Rc) de la proporción 1.   Tabla 2      Tamaño muestral necesario por grupo, según            proporciones que se comparan            (p1, p2), para hipótesis unilateral, dado error alfa de 0,05            y beta de 0,20*         p2  p1               0,80      0,70      0,60      0,50      0,40      0,30      0,20           0,60 73               0,50 36 84             0,40  23 41 85           0,30 15 23 42 84         0,20 10 15 23 36 73       0,10 8 10 13 19 30 56 67   0,05 6 9 11 14 20 34          * Modificado de referencia          10.          En su calculadora arcsen sería sen elevado a -    1.        La prueba de hipótesis que se supone se empleará    con los resultados del estudio es Ji2.       IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA  Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.    Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que        a/(a+c)      LR+ =           b/(b+d)       En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).    Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%.   La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12.  El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo.  Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:   N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2      N´ =        r (p2 - p1)2   siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 Para una diferencia determinada, el tamaño muestral requerido no es    constante y depende de las proporciones entre las cuales se establece la diferencia.    Así, podemos ver al mismo tiempo que los resultados también dependen    del programa empleado, suponiendo que dejamos fijo el error alfa en 0,05 y el    error beta en 0,20 (tabla 1). Las cifras continúan    reduciéndose en espejo luego de haber ascendido a un máximo.      El programa Epilnfo emplea la fórmula de Fleiss4    y el Win Episcope 1,0 declara la de Snedecor y Cochran7.       En la eventualidad de poder establecer sólo la diferencia que interesa    detectar entre proporciones o porcentajes y los errores respectivos, la elección    de la muestra deberá corresponder, entonces, a la cifra mayor como ya    señaláramos anteriormente.       Tabla 1       Tamaño muestral para una diferencia de 0,15            entre dos proporciones según valores            de estas y programa estadístico utilizado, dado error alfa de            0,05 y beta de 0,20         Proporciones  Diferencia   Casos necesarios por grupo según programa                          Epilnfo 6.04     Win Episcope 1.08                      0,05 y 0,20            0,10 y 0,25            0,15 y 0,30            0,20 y 0,35            0,25 y 0,40            0,30 y 0,45            0,35 y 0,50            0,40 y 0,55            0,45 y 0,60            0,50 y 0,65            0,55 y 0,70                        0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15                        88            113            134            151            165            176            183            186            186            183            176                        74            98            119            137            151            161            168            172            172            168            161                       III. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES POR PRUEBA DE    FISHER-IRWIN DE PROBABILIDADES EXACTAS    En ocasiones, se puede presumir que en la investigación se incluirá    una muestra pequeña y se compararán dos grupos por la mencionada    prueba de hipótesis9.   Se dispone de tablas que proporcionan el tamaño muestral por grupo    requerido para satisfacer los errores alfa y beta planteados frente a la comparación    de dos proporciones10. A modo de ejemplo señalaremos    los datos que se proporcionan en la tabla 2.   El cálculo del tamaño muestral para estudiar la diferencia entre    dos proporciones en tabla de 2 x 2, con hipótesis unilateral, incluye    las dos proporciones y los errores alfa y beta. Debe contemplarse una proporción    como "control" o valor "patrón" (pl) y la otra sería "experimental"    (p2). En tales condiciones:      N = 1.641,6    [   (Za        + Zß)               (arcsen Rc p1 - arcsen Rc p2)  ]   2    donde Za es 1,64 si alfa es 0,05 para prueba unilateral    y 1,96 si es bilateral, Zß es 0,84 si beta es 0,20 para prueba uni o bilateral,    arcsen Rc p1 es el arcsen (corresponde "al ángulo cuyo seno es el valor    dado") de la raíz cuadrada (Rc) de la proporción 1.   Tabla 2      Tamaño muestral necesario por grupo, según            proporciones que se comparan            (p1, p2), para hipótesis unilateral, dado error alfa de 0,05            y beta de 0,20*         p2  p1               0,80      0,70      0,60      0,50      0,40      0,30      0,20           0,60 73               0,50 36 84             0,40  23 41 85           0,30 15 23 42 84         0,20 10 15 23 36 73       0,10 8 10 13 19 30 56 67   0,05 6 9 11 14 20 34          * Modificado de referencia          10.          En su calculadora arcsen sería sen elevado a -    1.        La prueba de hipótesis que se supone se empleará    con los resultados del estudio es Ji2.       IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA  Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.    Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que        a/(a+c)      LR+ =           b/(b+d)       En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).    Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%.   La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12.  El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo.  Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:   N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2      N´ =        r (p2 - p1)2   siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

El programa Epilnfo emplea la fórmula de Fleiss4    y el Win Episcope 1,0 declara la de Snedecor y Cochran7.       En la eventualidad de poder establecer sólo la diferencia que interesa    detectar entre proporciones o porcentajes y los errores respectivos, la elección    de la muestra deberá corresponder, entonces, a la cifra mayor como ya    señaláramos anteriormente.       Tabla 1       Tamaño muestral para una diferencia de 0,15            entre dos proporciones según valores            de estas y programa estadístico utilizado, dado error alfa de            0,05 y beta de 0,20         Proporciones  Diferencia   Casos necesarios por grupo según programa                          Epilnfo 6.04     Win Episcope 1.08                      0,05 y 0,20            0,10 y 0,25            0,15 y 0,30            0,20 y 0,35            0,25 y 0,40            0,30 y 0,45            0,35 y 0,50            0,40 y 0,55            0,45 y 0,60            0,50 y 0,65            0,55 y 0,70                        0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15                        88            113            134            151            165            176            183            186            186            183            176                        74            98            119            137            151            161            168            172            172            168            161                       III. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES POR PRUEBA DE    FISHER-IRWIN DE PROBABILIDADES EXACTAS    En ocasiones, se puede presumir que en la investigación se incluirá    una muestra pequeña y se compararán dos grupos por la mencionada    prueba de hipótesis9.   Se dispone de tablas que proporcionan el tamaño muestral por grupo    requerido para satisfacer los errores alfa y beta planteados frente a la comparación    de dos proporciones10. A modo de ejemplo señalaremos    los datos que se proporcionan en la tabla 2.   El cálculo del tamaño muestral para estudiar la diferencia entre    dos proporciones en tabla de 2 x 2, con hipótesis unilateral, incluye    las dos proporciones y los errores alfa y beta. Debe contemplarse una proporción    como "control" o valor "patrón" (pl) y la otra sería "experimental"    (p2). En tales condiciones:      N = 1.641,6    [   (Za        + Zß)               (arcsen Rc p1 - arcsen Rc p2)  ]   2    donde Za es 1,64 si alfa es 0,05 para prueba unilateral    y 1,96 si es bilateral, Zß es 0,84 si beta es 0,20 para prueba uni o bilateral,    arcsen Rc p1 es el arcsen (corresponde "al ángulo cuyo seno es el valor    dado") de la raíz cuadrada (Rc) de la proporción 1.   Tabla 2      Tamaño muestral necesario por grupo, según            proporciones que se comparan            (p1, p2), para hipótesis unilateral, dado error alfa de 0,05            y beta de 0,20*         p2  p1               0,80      0,70      0,60      0,50      0,40      0,30      0,20           0,60 73               0,50 36 84             0,40  23 41 85           0,30 15 23 42 84         0,20 10 15 23 36 73       0,10 8 10 13 19 30 56 67   0,05 6 9 11 14 20 34          * Modificado de referencia          10.          En su calculadora arcsen sería sen elevado a -    1.        La prueba de hipótesis que se supone se empleará    con los resultados del estudio es Ji2.       IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA  Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.    Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que        a/(a+c)      LR+ =           b/(b+d)       En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).    Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%.   La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12.  El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo.  Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:   N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2      N´ =        r (p2 - p1)2   siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 En la eventualidad de poder establecer sólo la diferencia que interesa    detectar entre proporciones o porcentajes y los errores respectivos, la elección    de la muestra deberá corresponder, entonces, a la cifra mayor como ya    señaláramos anteriormente.       Tabla 1       Tamaño muestral para una diferencia de 0,15            entre dos proporciones según valores            de estas y programa estadístico utilizado, dado error alfa de            0,05 y beta de 0,20         Proporciones  Diferencia   Casos necesarios por grupo según programa                          Epilnfo 6.04     Win Episcope 1.08                      0,05 y 0,20            0,10 y 0,25            0,15 y 0,30            0,20 y 0,35            0,25 y 0,40            0,30 y 0,45            0,35 y 0,50            0,40 y 0,55            0,45 y 0,60            0,50 y 0,65            0,55 y 0,70                        0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15            0,15                        88            113            134            151            165            176            183            186            186            183            176                        74            98            119            137            151            161            168            172            172            168            161                       III. ESTUDIOS EN QUE SE COMPARARÁN DOS PROPORCIONES POR PRUEBA DE    FISHER-IRWIN DE PROBABILIDADES EXACTAS    En ocasiones, se puede presumir que en la investigación se incluirá    una muestra pequeña y se compararán dos grupos por la mencionada    prueba de hipótesis9.   Se dispone de tablas que proporcionan el tamaño muestral por grupo    requerido para satisfacer los errores alfa y beta planteados frente a la comparación    de dos proporciones10. A modo de ejemplo señalaremos    los datos que se proporcionan en la tabla 2.   El cálculo del tamaño muestral para estudiar la diferencia entre    dos proporciones en tabla de 2 x 2, con hipótesis unilateral, incluye    las dos proporciones y los errores alfa y beta. Debe contemplarse una proporción    como "control" o valor "patrón" (pl) y la otra sería "experimental"    (p2). En tales condiciones:      N = 1.641,6    [   (Za        + Zß)               (arcsen Rc p1 - arcsen Rc p2)  ]   2    donde Za es 1,64 si alfa es 0,05 para prueba unilateral    y 1,96 si es bilateral, Zß es 0,84 si beta es 0,20 para prueba uni o bilateral,    arcsen Rc p1 es el arcsen (corresponde "al ángulo cuyo seno es el valor    dado") de la raíz cuadrada (Rc) de la proporción 1.   Tabla 2      Tamaño muestral necesario por grupo, según            proporciones que se comparan            (p1, p2), para hipótesis unilateral, dado error alfa de 0,05            y beta de 0,20*         p2  p1               0,80      0,70      0,60      0,50      0,40      0,30      0,20           0,60 73               0,50 36 84             0,40  23 41 85           0,30 15 23 42 84         0,20 10 15 23 36 73       0,10 8 10 13 19 30 56 67   0,05 6 9 11 14 20 34          * Modificado de referencia          10.          En su calculadora arcsen sería sen elevado a -    1.        La prueba de hipótesis que se supone se empleará    con los resultados del estudio es Ji2.       IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA  Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.    Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que        a/(a+c)      LR+ =           b/(b+d)       En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).    Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%.   La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12.  El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo.  Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:   N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2      N´ =        r (p2 - p1)2   siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 Tabla 1  

  

 En ocasiones, se puede presumir que en la investigación se incluirá    una muestra pequeña y se compararán dos grupos por la mencionada    prueba de hipótesis9. 

 Se dispone de tablas que proporcionan el tamaño muestral por grupo    requerido para satisfacer los errores alfa y beta planteados frente a la comparación    de dos proporciones10. A modo de ejemplo señalaremos    los datos que se proporcionan en la tabla 2. 

 El cálculo del tamaño muestral para estudiar la diferencia entre    dos proporciones en tabla de 2 x 2, con hipótesis unilateral, incluye    las dos proporciones y los errores alfa y beta. Debe contemplarse una proporción    como "control" o valor "patrón" (pl) y la otra sería "experimental"    (p2). En tales condiciones: 

    N = 1.641,6    [   (Za        + Zß)               (arcsen Rc p1 - arcsen Rc p2)  ]   2    donde Za es 1,64 si alfa es 0,05 para prueba unilateral    y 1,96 si es bilateral, Zß es 0,84 si beta es 0,20 para prueba uni o bilateral,    arcsen Rc p1 es el arcsen (corresponde "al ángulo cuyo seno es el valor    dado") de la raíz cuadrada (Rc) de la proporción 1.   Tabla 2      Tamaño muestral necesario por grupo, según            proporciones que se comparan            (p1, p2), para hipótesis unilateral, dado error alfa de 0,05            y beta de 0,20*         p2  p1               0,80      0,70      0,60      0,50      0,40      0,30      0,20           0,60 73               0,50 36 84             0,40  23 41 85           0,30 15 23 42 84         0,20 10 15 23 36 73       0,10 8 10 13 19 30 56 67   0,05 6 9 11 14 20 34          * Modificado de referencia          10.          En su calculadora arcsen sería sen elevado a -    1.        La prueba de hipótesis que se supone se empleará    con los resultados del estudio es Ji2.       IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA  Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.    Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que        a/(a+c)      LR+ =           b/(b+d)       En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).    Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%.   La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12.  El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo.  Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:   N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2      N´ =        r (p2 - p1)2   siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

donde Za es 1,64 si alfa es 0,05 para prueba unilateral    y 1,96 si es bilateral, Zß es 0,84 si beta es 0,20 para prueba uni o bilateral,    arcsen Rc p1 es el arcsen (corresponde "al ángulo cuyo seno es el valor    dado") de la raíz cuadrada (Rc) de la proporción 1. 

 Tabla 2      Tamaño muestral necesario por grupo, según            proporciones que se comparan            (p1, p2), para hipótesis unilateral, dado error alfa de 0,05            y beta de 0,20*         p2  p1               0,80      0,70      0,60      0,50      0,40      0,30      0,20           0,60 73               0,50 36 84             0,40  23 41 85           0,30 15 23 42 84         0,20 10 15 23 36 73       0,10 8 10 13 19 30 56 67   0,05 6 9 11 14 20 34          * Modificado de referencia          10.          En su calculadora arcsen sería sen elevado a -    1.        La prueba de hipótesis que se supone se empleará    con los resultados del estudio es Ji2.       IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA  Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.    Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que        a/(a+c)      LR+ =           b/(b+d)       En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).    Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%.   La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12.  El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo.  Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:   N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2      N´ =        r (p2 - p1)2   siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

     Tamaño muestral necesario por grupo, según            proporciones que se comparan            (p1, p2), para hipótesis unilateral, dado error alfa de 0,05            y beta de 0,20*         p2  p1               0,80      0,70      0,60      0,50      0,40      0,30      0,20           0,60 73               0,50 36 84             0,40  23 41 85           0,30 15 23 42 84         0,20 10 15 23 36 73       0,10 8 10 13 19 30 56 67   0,05 6 9 11 14 20 34          * Modificado de referencia          10.          En su calculadora arcsen sería sen elevado a -    1.        La prueba de hipótesis que se supone se empleará    con los resultados del estudio es Ji2.       IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA  Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.    Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que        a/(a+c)      LR+ =           b/(b+d)       En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).    Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%.   La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12.  El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo.  Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:   N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2      N´ =        r (p2 - p1)2   siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 

    En su calculadora arcsen sería sen elevado a -    1.        La prueba de hipótesis que se supone se empleará    con los resultados del estudio es Ji2.       IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA  Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.    Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que        a/(a+c)      LR+ =           b/(b+d)       En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).    Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%.   La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12.  El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo.  Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:   N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2  donde:       [(Za{(r        + 1) pq}1/2)- Zß {r p1q1 + p2q2}1/2]2      N´ =        r (p2 - p1)2   siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 IV. ESTUDIOS EN QUE SE INVESTIGARÁ UNA PRUEBA DIAGNÓSTICA

 Para estos se requiere conocer: error alfa, error beta, proporción    esperada de falsos positivos o la especificidad, razón de verosimilitud    considerada digna de ser detectada, intervalo de confianza deseado para la sensibilidad    y la prevalencia esperada de la patología en estudio. El procedimiento    de cálculo en detalle se puede encontrar en otra parte11.  

 Las razones de verosimilitud (likelihood ratios) (LR), índices    fijos como sensibilidad y especificidad ofrecen una relación entre las    cuatro casillas de la tabla de 2 x 2, en que se estudia una prueba diagnóstica:    a, b, c, d. Es así como, si consideramos un LR+, veremos que tal    resultado se obtiene de la razón entre las proporciones a/(a+c) y b/(b+d)    de modo que 

 

 En esta división, el numerador corresponde a la sensibilidad de la    prueba y el denominador a la proporción de falsos positivos (1-especificidad).  

 Es posible, entonces, plantear la búsqueda del tamaño muestral    a partir de una comparación de dos proporciones (LR), en prueba unilateral    (puesto que se espera que el numerador será mayor que el denominador,    LR+ veces), para lo cual se requeriría estimar los falsos positivos (o    la especificidad) probables en esa prueba y la prevalencia esperada del trastorno    en estudio dentro de la muestra. Al mismo tiempo, se debe elegir un valor de    LR+ digno de ser detectado, contemplando el nivel de error alfa    y beta que se considere adecuado. Tal comparación es entre dos    proporciones independientes (aunque intrínsecamente relacionadas) y de    tamaño casi siempre diferente, con una proporción de verdaderos    enfermos habitualmente inferior a 50%. 

 La estimación de los falsos positivos determina en parte el LR+ elegible,    puesto que, si los primeros constituyen un 5%, es poco probable que interese    un LR+ de 3 si se considera que 5% x 3 indicará la sensibilidad de la    prueba en tal caso, es decir, 15% y esta seguramente no resultaría de    mucho interés al investigador como nivel inicial de detección.    Del mismo modo, si la proporción de falsos positivos fuera muy alta,    LR+ puede tener como límite un valor sorprendentemente bajo. Por ejemplo,    una cifra de falsos positivos del 30% (0,30) tiene un LR+ límite posible    de 3,33, ya que una cifra mayor supondría una sensibilidad de la prueba    superior al 100%. Como sea, es generalmente aceptado que LR+ en el margen de    2 a 5 suele ser de importancia en el sentido que el cambio de la probabilidad    preprueba a aquella posprueba cuando LR+ está en esos valores, sería    de una magnitud de consideración12. 

El poder estimar algunos valores, como la proporción de falsos positivos,    requiere algún conocimiento previo de la situación o efectuar    un estudio piloto para obtenerlo. 

Aceptando que se cumplen los requisitos para efectuar la correspondiente prueba    de hipótesis, de acuerdo con Fleiss4 tendríamos:  

N = (N´/4) (1 + {1 + 2 (r +1)/N´r | p2 - p1|}1/2)2 

donde: 

siendo N uno de los tamaños muestrales y Nr el otro, r la fracción    que representa la muestra más pequeña respecto a la mayor, p1    = a/(a+c) que indica la sensibilidad de la prueba y es igual a p2 x LR+, q1    = 1 - p1, p2 = b/(b+d) y corresponde a la proporción de falsos positivos    (1-especificidad), q2 = 1 - p2, Z? para hipótesis unilateral es 1,645    (para un error alfa de 0,05) o 2,326 (para un error alfa de 0,01), Zß    es - 0,842 (para un error beta de 0,20), –1,29 (para un error beta de 0,10)    o - 1,645 (para un error beta de 0,05), p = (p1 + rp2) / (r + 1) y q = 1 - p.    Como lo esperable es una prevalencia inferior a 50%, la muestra que corresponde    a verdaderos enfermos según estándar ideal será Nr y la    de verdaderos no afectados N.      Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

Ahora bien, podemos indicar que para detectar un LR+ de 2,5 o mayor (en hipótesis    unilateral), con un error alfa de 5% y beta de 10%, es decir, una potencia del    estudio de 90%, contemplando una prevalencia de afectados por la patología    de interés de 25% en la muestra y falsos positivos de 22%, se requiere    estudiar un total de 111 casos. Estos se encontrarán distribuidos como    28 y 83 casos. Si la estimación de falsos positivos fuera más    alta o más baja se requeriría, respectivamente, menos y más    casos integrando la muestra, si no se modifica la LR+ escogida.       Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 Efectuada esta primera fase del cálculo, podemos perfeccionarla estableciendo    el intervalo de confianza (IC) que se considere apropiado o aceptable para la    sensibilidad. El intervalo de confianza del 95% (IC95%) de p1 0,55 o 55% puede    establecerse, por ejemplo, en ± 10%.       El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 El error estándar deseado sería 10/1,96, es decir 5,10.       Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 Se puede calcular el número de casos necesarios para generar ese error    estándar, contemplando que el procedimiento se modifica si la proporción    se aleja mucho de 0,50. El siguiente cálculo es adecuado para muestras    no muy pequeñas y proporción no menor de 0,30 o mayor de 0,70.    Varios programas computacionales proporcionan este cálculo. Como sea,    para los fines perseguidos, no se requiere extrema precisión. Entonces    5,10 = ((100-55) x 55 / n)1/2 y despejando n obtenemos 95 casos.    Esto significa que para lograr el intervalo de confianza deseado el número    de afectados por la patología de interés debe ser de 95 en vez    de 28 casos y por lo tanto, conservando la prevalencia estimada, el segundo    grupo debería ser de 285 casos en vez de 83. Esto nos da un N total final    de 383 casos.      Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

Hay que destacar lo siguiente: si el nivel de sensibilidad encontrado (0,55),    tan cercano a 0,50, fuese mayor o menor, el número de casos encontrado    (95) generaría un intervalo de confianza más estrecho. Dicho de    otro modo, en tales circunstancias se requeriría una muestra menor.       Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 Por otro lado, el intervalo de confianza de p2 será al menos tan estrecho    como el de la sensibilidad si la prevalencia es menor que 0,50, como es usual.    Pero si no es así y la prevalencia supera 0,50, para la muestra calculada    el intervalo de confianza de p2 será más ancho que lo deseado.       Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 Es necesario tener presente que el tamaño de la muestra, para un mismo    LR+, cambiará substancialmente con la proporción de falsos positivos.    Así, si se establece un LR+ deseable de detectar igual o mayor que 3    y p2 es 0,20, consecuentemente p1 será 0,60 y la diferencia a detectar    0,40 (40%). Para ello se requerirá una muestra pequeña por tratarse    de una gran diferencia. Sin embargo, si p2 fuese 0,05, p1 debiera ser 0,15 y    la diferencia a detectar sólo de 0,10 (10%), por lo que se requerirá    una muestra mucho mayor.      Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

Si se comenzara con la sensibilidad (p1) y su intervalo de confianza para conocer    el respectivo tamaño de la muestra para esa proporción, según    "r" sería posible conocer la segunda muestra parcial. Sin embargo, de    todas maneras se requiere verificar que el N total no es insuficiente para los    errores alfa y beta establecidos, particularmente si el valor de p1 se aleja    de 0,50, donde se encontrará un "n" más pequeño para el    mismo IC y asimismo si la prevalencia supera 0,50, donde la muestra de no afectados    sería menor que la de enfermos, con un IC mayor que el deseado para el    grupo de afectados.        V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

  V. ESTUDIOS EN QUE SE COMPARARÁN DOS PROMEDIOS   Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores.   Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta.  La fórmula:   

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 Aunque lo más corriente es que se trabaje con los elementos que se    señalan a continuación, es posible que se exija estimar las desviaciones    estándar de los grupos además de las diferencias de promedios    y los errores. 

 Para esto se requiere establecer el valor del promedio esperado de la variable    en el grupo 1 (01), el valor promedio esperado de la variable en el grupo 2    (02), estimar un valor para la desviación estándar de la variable    (DE), error alfa y error beta. 

La fórmula: 

 

 Es posible ver que en este cálculo no se requiere conocer cada promedio,    pudiendo entonces establecerse sólo la diferencia clínicamente    significativa. La dispersión de los valores, la desviación estándar,    es frecuente que no se conozca o bien que se disponga de un valor obtenido en    un estudio piloto u otra investigación con pocos casos. Aquí es    de interés poder calcular el intervalo de confianza de la desviación    estándar que se disponga, con el fin de establecer un margen de valores    con los cuales determinar el tamaño muestral mayor y menor. Supongamos    que en un estudio piloto sobre 20 casos se encuentra la variable de interés    con promedio de 254 y desviación estándar de 31. Se desea poder    detectar una diferencia entre promedios de 18. En estas condiciones, el intervalo    de confianza del 95% para la desviación estándar es de 23,7 a    44,6 y el tamaño muestral va desde 28 a 96 casos por grupo.       Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 Puesto que la desviación estándar de la muestra es un estimador    sesgado de la desviación estándar del universo del cual procede    el grupo, señalaremos los factores de corrección apropiados para    obviar el sesgo y luego aquellos que establecen el intervalo de confianza del    95% (tabla 3)13.       Tabla 3      Factores para corregir sesgo de la desviación            estándar muestral (DE)            y para obtener el intervalo de confianza de esta (IC),            según tamaño de la muestra (n)*           n     Factor de corrección  del sesgo de DE     IC 95% de DE  Factores                      10            15            20            25            30            35            40            45            50            55            60            80            90            100                        1,025            1,016            1,012            1,010            1,008            1,007            1,006            1,005            1,005            1,004            1,004            1,003            1,002            1,002                        0,69-1,75            0,64-1,54            0,76-1,44            0,78-1,38            0,80-1,34            0,81-1,30            0,82-1,23            0,83-1,26            0,84-1,24            0,84-1,23            0,85-1,22            0,87-1,18            0,87-1,17            0,88-1,16                    * Modificado de referencia          13.     Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés.   Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral.   Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13.   De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.   VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 Tabla 3 



Recordemos que en la comparación de promedios se presume que las muestras    proceden de poblaciones con igual varianza y distribución normal de la    variable de interés. 

 Es necesario tener cuidado de no caer en la siguiente situación al    estimar el tamaño de la muestra si se van a comparar dos promedios: Ud.    puede efectuar el cálculo señalando que espera detectar una diferencia    entre promedios de igual magnitud que la desviación estándar,    sin conocer esta. Ello originará por grupo siempre el mismo tamaño,    de modo que en realidad no estará efectuando un cálculo del tamaño    muestral. 

 Una observación adicional de interés es la siguiente: cuando    la información disponible se refiere a un grupo considerado normal, la    desviación estándar, como referencia para el cálculo del    tamaño de la muestra, no es muy acertada si consideramos que enfermos    de esa misma población mostrarán casi de seguro una varianza mayor.    Ello tiene su interés, puesto que al comparar promedios en dos grupos,    uno sano y otro enfermo, van a diferir seguramente por las varianzas y la comparación    de promedios no se podrá efectuar sin recurrir a correcciones como Welch    o Satterwaithe13. 

 De cualquier manera, aunque no discutiremos la conveniencia de utilizar como    medidas de resultado los promedios de una variable, hay circunstancias en que    su indicación no es la óptima, particularmente si se desea hacer    cálculo del número de casos necesario de tratar (NNT) y derivado    de ello una estimación económica. En tales situaciones se requiere    establecer en los grupos estudiados usualmente la proporción que mejora,    que sufre daño, etc. Por otro lado para algunas variables, donde no se    analiza resultados de un tratamiento, podrá ser apropiado el estudio    de promedios: tal sería la situación de comparar, por ejemplo    gasto energético en reposo de eutróficos y obesos.

  VI. ESTUDIOS EN QUE UN GRUPO SERÁ SU PROPIO CONTROL  Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta.  La fórmula a utilizar será:  N = [(Za + Zß)2     DEd2 ] / dif2   VII. ESTUDIOS DE CONCORDANCIA    En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

Cuando cada caso será su propio control y se empleará la "t"    de Student para muestras relacionadas, se requiere conocer o estimar la diferencia    a detectar (dif), la varianza esperada de las diferencias experimentadas por    el grupo en los dos momentos estudiados (DEd2), el error alfa y el    error beta. 

La fórmula a utilizar será: 

N = [(Za + Zß)2     DEd2 ] / dif2 

 En estudios de concordancia conviene recordar que el índice kappa tiene    una distribución normal si el efectivo de la muestra es mayor que 2 g5,    siendo "g" el número de categorías en investigación. En    tales circunstancias se puede verificar la hipótesis de k = 0. La comparación    de dos índices kappa requiere un tamaño muestral mínimo    de 3 g2 para poder intentarla14. Otro    asunto es establecer cuántos casos se requiere estudiar en una situación    específica para detectar un índice kappa como diferente de cero    o para comparar dos índices. Lo usual es tener que efectuar un estudio    piloto. Supongamos que en un estudio de 50 casos dos observadores clínicos    califican los casos como con o sin una determinada manifestación clínica    como se señala en la tabla 4.       Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 Tabla 4      Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

     Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica             Observador A                con     sin     total            con              25                        10                        25              Observador B             sin  5  20 25           total             20                        30                        50                   * Explicación en          el texto     En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%).   Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde        EE k=0 = (pc / N (1-pc ) )1/2    donde  pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 

En esta, la prevalencia del hallazgo según el observador A fue de 20/50    (40%) con IC 95% (26,7 - 54,8%) y la prevalencia del hallazgo según observador    B fue de 25/50 (50%) con IC 95% (35,7 - 64,3%). 

 Recordemos que si se desea establecer el número de casos necesario    para detectar un índice kappa como significativamente diferente de cero    (p < 0,05) se requiere calcular primero el error estándar de kappa    = 0, donde 

      EE k=0 = (pc / N (1-pc ) )1/2    donde 

pc es la proporción de concordancia dada por el azar y N    el número de casos a estudiar. El valor de pc se puede determinar    según el intervalo de confianza de la prevalencia del hallazgo clínico    para cada observador, de la manera siguiente: Tomamos las prevalencias menores,    sabiendo que el total de la tabla es "1" o 100%, de tal manera que conociendo    los marginales 0,357 y 0,267 podemos calcular los faltantes, como se muestra    en la tabla 5.       Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

  Tabla 5        Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 

     Estudio de concordancia entre dos observadores según            presencia de una manifestación clínica.            Determinación de pc*             Observador A                con     sin     total            con              0,095                            0,357              Observador B             sin    0,471 0,643          total             0,567                        0,733                        1          * Explicación en el texto            Ahora, teniendo los marginales correspondientes a las casillas "a" y "d", podemos  calcular a su vez los valores esperados en esas casillas (0,095 resulta de 0,357  por 0,267, dividido por el total "1"). Finalmente, pc es igual a la suma de 0,095  y 0,471, es decir 0,566. Por este procedimiento podemos llegar a saber que pc  fluctuará entre 0,43 y 0,56. Entonces, si se desea detectar como significativamente  diferente de cero un índice kappa de 0,25 o mayor, podemos decir que el  error estándar de kappa igual a cero debe ser de 0,25/ 1,96, es decir 0,127.  Disponiendo del valor pc y del error estándar de kappa = 0 podemos resolver  "N" de la fórmula indicada más arriba. Así, obtenemos que  "N" fluctuará entre 47 y 79 casos. El tamaño muestral será  entonces de 79 casos.        VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 

  VIII. ESTUDIOS DE COHORTES    En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß".   La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:           N = (n'/4)    [   1 + Rc (    (1 + 2 (c +1)               n'c |p0  (RR – 1)|   )]   2    donde       [Za         Rc {(c + 1) p (1-p)} + Zß Rc {cp0 (1-p0) + pRR (1-p0RR)}]2     n´=          c [p0 (1-RR)]2    y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.    Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos.   IX. ESTUDIOS CASO - CONTROL    Un desarrollo detallado del problema se puede encontrar en otra parte15.    Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta.  La fórmula para estudios no pareados es:       [Za        Rc (2 p q) + Zß Rc (p1q1 + p0q0)]2    N =         (p1 – p0)2    donde  p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0.   Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada.  1. Departamento de Pediatrìa y Cirugía Infantil,    Campus Norte, Facultad de Medicina, Universidad de Chile.  REFERENCIAS 1. Edmiston ChE, Josephson A, Pottinger J, Ciacco-Tsivitis    M, Palenik Ch: The numbers game: Sample-size determination. AJIC 1993; 21:    151-154.         [ Links ]2. Essex-Sorlie D: Medical Biostatistics & Epidemiology.    Appleton & Lange, Norwalk,USA, 1995: 124-126.         [ Links ]3. Matthews DE, Farewell VT: Estadística Médica.    Salvat Editores SA, Barcelona, España, 1988: 93-107.         [ Links ]4. Fleiss JL: Statistical methods for rates and proportions.    2nd edition, John Wiley & Sons, 1981: 38-48.         [ Links ]5. C.D.C., U.S.A. EpiInfo 6.04a. W.H.O., Geneva, Switzerland,    1996 .         [ Links ]6. Méndez B, Duffau G: Neumonía grave    en lactantes: Balance de agua. Acta Pediatr Esp 1998; 56: 437-443.         [ Links ]7. Snedecor GW, Cochran L: Statistical methods. 7th    edition, The Iowa State University Press, 1986: 89-122.         [ Links ]8. Blas N, Ortega C, Frankena K, Noordhuizen J: Win    Episcope 1.0a. Veterinary Faculty, Zaragoza and Agricultural University, Wageningen,    1996.         [ Links ]9. Duffau G, Emilfork M: Solución hipotónica    para hidratación oral. Acta Pediatr Esp 1992; 50: 235-244.         [ Links ]10. Haseman JK: Exact sample size for use with the    Fisher-Irwin test for 2 x 2 tables. Biometrics 1978; 34: 106-109.         [ Links ]11. Duffau G: Tamaño muestral en estudios sobre    pruebas diagnósticas. Rev Chil Pediatr 1998; 69: 122-125.         [ Links ]12. Steel R, Torrie J: Bioestadística: Principios    y procedimientos. Madrid: McGraw-Hill, 1990: 102-105.         [ Links ]13. Lentner C: Introduction to statistics in: Scientific    tables, 8th edition, Switzerland: Ciba-Geigy Ltd., 1982: 209.         [ Links ]14. Kramer M, Feinstein A: Clinical biostatistics.    LIV. The biostatistics of concordance. Clin Pharmacol Ther 1981; 29: 111-123.          [ Links ]15. Herrera P, Duffau G: Estudio Caso-Control. Editorial    Mediterráneo, Santiago de Chile 1997: 61-70.         [ Links ] 

 En estos se requiere2,3 conocer    p0 (que corresponde a la frecuencia de la condición en estudio en la    población no expuesta y se expresa como decimales: 0,05 (5%), RR (que    corresponde al riesgo relativo que se considere digno de ser detectado (o mayor).    RR de uno significa que el factor de exposición no se encuentra asociado    a un aumento del riesgo, puesto que este es igual en expuestos y no expuestos),    c que es la relación numérica de expuestos/no expuestos (muestra    si las cohortes son de igual tamaño o no), error alfa y su respectivo    "Za", y error beta y su respectivo "Zß". 

 La fórmula proporciona el número de expuestos requeridos y,    naturalmente, el de no expuestos como c  N:      

donde 

y Rc es raíz cuadrada, p = [(p0  RR ) + (p0 + c)] / (1 + c) y q = 1-p.  

 Un ensayo clínico controlado puede ser considerado un seguimiento de    dos cohortes, una expuesta al tratamiento experimental y la otra no. La similitud    se puede comprobar también en el cálculo del tamaño de    la muestra, que genera iguales resultados si se emplea RR de 3, como en el ejemplo    recién presentado, o se calcula con el resultado en la forma de 2 proporciones,    0,10 en los no expuestos y 0,30 en los expuestos. 

 Un desarrollo detallado del problema se puede encontrar en otra parte15.  

 Consideremos la situación de los estudios no pareados, en donde los    requisitos serán conocer la frecuencia relativa de exposición    entre los controles (p0), valor que puede resultar difícil de establecer.    Por otra parte, la investigación implica una situación de muy    baja prevalencia, por lo que la frecuencia de exposición en controles    y en la población total resultarán muy similares. Otro requisito    será la razón de riesgos (OR) de una magnitud digna de ser detectada    por considerarse que tiene interés para el investigador. Aunque no hay    una norma general para la elección, se suele considerar que OR inferior    a 2 probablemente carece de interés bien definido, por ello habitualmente    se escoge una cifra de 2 o más, aunque no muy alejada (3, 3,5 o valor    similar). También se requerirá establecer el error alfa y el error    beta. 

La fórmula para estudios no pareados es: 

donde 

p1 = p0 OR / [1 + p0 (OR - 1)], p = (p1 + p0)/ 2, q = 1 - p    q1 = 1- p1 y q0 = 1 - p0. 

 Como conclusión podemos señalar que destaca la importancia de    efectuar una estimación adecuada del tamaño muestral al iniciar    una investigación biomédica. Por otra parte, se hacen aparentes    las posibilidades de errar en este intento y la necesidad, la mayor parte de    las veces, de contar con apoyo y asesoría apropiada. 