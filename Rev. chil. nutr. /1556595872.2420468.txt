https://scielo.conicyt.cl/scielo.php?script=sci_arttext&pid=S0717-75182009000400011
ERRORES ESTADÍSTICOS FRECUENTES AL COMPARAR DOS POBLACIONES INDEPENDIENTES

  RESUMEN El objeto del presente trabajo es mostrar los    pasos metodológicos y estadísticos que los investigadores biomédicos deben realizar    para evitar una mala estimación de estadígrafos que son necesarios para establecer    hechos y, con ello, evitar inferencias teóricas erradas a partir de hechos empíricamente    mal construidos cuando se comparan dos poblaciones. Se enfatiza en las causas    posibles de este tipo de estimación y se proponen los pasos adecuados para evitar    dichas causas. Palabras clave: normalidad, homocedasticidad,    observaciones independientes, errores estadísticos, t-student   En algunos casos, los autores de estudios en    las áreas de la biomedicina, aplican pruebas estadísticas sin considerar las    restricciones que éstas tienen e ignoran el efecto real que las omisiones pueden    generar en los resultados y, como consecuencia, en el enfrentamiento de sus    resultados con la teoría 1. En el caso concreto de comparar dos o más poblaciones    existen cinco restricciones o condiciones que se deben cumplir estrictamente    para realizar este tipo de análisis (1-3): 1) Las observaciones deben ser independientes    entre si; 2) Las observaciones deben hacerse en poblaciones distribuidas normalmente;    3) Estas poblaciones tienen que tener homocedasticidad (igualdad de varianzas)    (o, en casos especiales deben tener una proporción de varianzas conocidas);    4) Las variables correspondientes deben ser cuantitativas continuas y 5) Cuando    existen más de dos poblaciones comparadas, las medias de estas poblaciones normales    y homocedásticas deben ser combinaciones lineales de efectos debidos a las columnas    y a las filas o a ambos. Cuando estas condiciones se satisfacen, entonces se    puede aplicar la prueba "t" o "F", según sea el caso. En la situación en que existe el interés de comparar    dos poblaciones es necesario que se cumplan las condiciones desde la 1 hasta    la 4 para que se pueda aplicar la prueba t-student. (1- 6) Como consecuencia    (asumiendo que las condiciones 1 y 4 se cumplen a priori, lo cual no necesariamente    es así), cada vez que un investigador desee comparar dos grupos de datos mediante    esta prueba, debe necesariamente examinar la normalidad de los mismos en ambos.    Tal normalidad, puede demostrarse empleado algunas de las pruebas que existen    al respecto: Anderson-Larning (7), Kolmogorov-Smirnov (8,9) (con la corrección    de Lilliefore) (9) y Shapiro-Wilk (10), entre otras (11). Una vez comprobada tal normalidad, se debe probar    homocedasticidad. Para este efecto existen pruebas lo suficientemente robustas,    tales como la de Levene (3,11,12) o la de Bartlett (13), entre otras (4). Si    las varianzas resultan iguales es necesario aplicar la prueba t-student específica    para estos casos (1,5,14); en caso contrario, si las varianzas resultan desiguales    se aplica una forma especial de la prueba en análisis, la cual es la t' -student    (t prima) (1,3). Si el supuesto de normalidad no se cumple y, además, no se    considera la presencia o ausencia de homocedasticidad para determinar el tipo    de prueba a aplicar, entonces surge la posibilidad de transformar los datos    (1,3,4,15). El tipo de transformación depende de la estructura y naturaleza    de los valores de la variable, del comportamiento de las varianzas y de las    medias de los valores de las variables (13,15). La transformación de los datos    busca normalizar la distribución no normal de los datos originales o igualdad    de varianzas entre los "tratamientos" o ambos al mismo tiempo. Luego    de transformar los datos, se aplican algunas de las pruebas antes descritas    y, se verifica el supuesto y la homocedasticidad bajo las condiciones de datos    transformados. Si se cumple la normalidad, se puede aplicar la prueba t correspondiente,    en concordancia con la relación entre varianzas observadas (1). Bajo las circunstancias de que la normalidad    no se cumplen y no se considera la presencia o ausencia de homocedasticidad,    aún después de trasformar los datos adecuadamente (1,2,4,15) y el investigador    insiste en aplicar la prueba t "tradicional" (a datos originales o    transformados), se pierde Potencia (1-13) en la aplicación de la prueba y no    se puede controlar la probabilidad del error de Tipo I (a) (2), lo que puede    conducir a encontrar significaciones estadísticas donde no existen o viceversa.    Esto sólo tiene una traducción posible: los hechos que emanan del resumen estadístico    no tienen validez ninguna y, por tanto, toda inferencia teórica sobre su base    podría contener errores. Se han reunido pruebas empíricas demostrando que las    desviaciones ligeras de los supuestos intrínsecos de las pruebas paramétricas    no pueden tener efectos radicales en la cifra de probabilidad obtenida (2,5,6)    o que el uso de un diseño aleatorizado permite probar hipótesis sin necesidad    de suponer la forma de la distribución (5,6), pero el problema que surge es    el hecho de que aún no se sabe que se entiende por "ligera desviación"    y, en el campo de la biomedicina, es muy frecuente que los sujetos no se asignen    al azar a los distintos tratamientos (grupos que se comparan: sanos y enfermos)    1. Como consecuencia, ante esta indefinición, es preferible adoptar un estilo    "ortodoxo" en el cual se manifieste la estricta demostración del cumplimiento    de cada supuesto antes señalado antes de usar la prueba adecuada para cada caso    (1,3). Si la normalidad no se cumple, no queda otra    alternativa que emplear las pruebas no paramétricas. Las alternativas no paramétricas    de la prueba de t-student más empleadas son las pruebas U de Mann-Whitney y    la prueba Z de Kolmogorov-Smirnov (1,3,13,15,16), entre otras (1,3,13,15-17),    las cuales han demostrado su eficacia y confiabilidad como alternativa (1,2,17). De lo antes planteado, surge el concepto de Potencia-    Eficiencia de una prueba, el cual se refiere al incremento del tamaño de muestra    necesario para hacer una prueba, por ejemplo, B tan poderosa como otra prueba    que llamaremos A, donde esta última es la más poderosa conocida (2). Las pruebas    paramétricas (t-student entre ellas) tienen mayor potencia-eficiencia que las    no paramétricas (2,17); por tal razón los investigadores deben preferir el uso    de pruebas paramétricas. Pero, ante la imposibilidad de su uso (por las razones    antes explicadas), se debe procurar las no paramétricas, tratando de incrementar    al máximo el tamaño de muestra (n) posible en ambos grupos de tal forma que    tal incremento permita, a su vez, aumentar la potencia perdida por la imposibilidad    de emplear pruebas paramétricas (2,17).   BIBLIOGRAFÍA 1. Díaz VR Metodología de la Investigación Científica    y Bioestadística para Profesionales y Estudiantes de Ciencias de la Salud. Primera    Edición. RiL Editores. Santiago. 2009. (en prensa).        [ Links ]2. Siegel S. Diseño experimental no paramétrico.    Editorial Científico-Técnica. La Habana. Cuba. 1972.        [ Links ]3. Ostle B. Estadística Aplicada. Editorial LIMUSA.    México. 1981.        [ Links ]4. Kuehl RO. Diseño de Experimentos. 2da. Edición.    Thomson Editores SA. México. 2001.        [ Links ]5. Montgomery DC Diseño y Análisis de Experimentos.    Primera Edición. Grupo Editorial Iberoamérica. México. 1991.        [ Links ]6. Box GE, Hunter WG, Hunter JS. Statistics for    Experimenters. 1st. ed. Wiley. NY. 1978.        [ Links ]7. Arnold SF. Mathematical Statistics. Prentice-Hall.    1990.        [ Links ]8. D'Agostino RB, Stephens MA. Goodness-of-Fit    Techniques. R.B. D'Agostino and M.A. Stephens, Eds. Edit. Marcel Dekke, Inc.    New York. 1986.        [ Links ]9. Lilliefore HW. "On the Kolmogorov-Smirnov    Test for Normality with Mean and Variance Unknown," J Am Stat Assoc 1967;    62: 399-402.        [ Links ]10. Shapiro S S, Wilk MB. An Analysis of Variance    Test for Normality (Complete Samples). Biometrika; 52: 591-598. 1965.        [ Links ]11. Hair JF, Anderson RE, Tatham RL, Black WC.    Analisis multivariante. Editorial Prentice-Hall. Madrid. 2001.        [ Links ]12. Levene H. Contributions to Probability and    Statistics. Stanford University Press. 1960.        [ Links ]13. Lerch G Diseño Experimental para las Ciencias    Agrícolas y Biológicas. Editorial Científico-Técnica. La Habana. 1977.        [ Links ]14. Hicks CR. Fundamental Concepts in the Design    of Experiments. Third Edition. CBC College Publishing. 1982.        [ Links ]15. Dixon WJ, Massey FJ. Introducción al análisis    estadístico. Instituto Cubano del Libro. La Habana. 1974.        [ Links ]16. Visauta B. Análisis estadístico con SPSS.    McGraw-Hill. Madrid. 1999.        [ Links ]17. Gibbons J.D. Nonparametric Methods for Quantitative    Analysis. Holt, Rhinehart, and Winston Edit. New. York. 1976.        [ Links ]  Este trabajo fue recibido el 21 de Mayo de 2009    y aceptado para ser publicado el 12 de Noviembre de 2009. Dirigir    la correspondencia a: 

Profesor Víctor Patricio Díaz Narváez        Facultad de Odontología Universidad Finis Terrae        Pedro de Valdivia 1509 Santiago. Chile. E-mail: vpdiaz@tie.cl 

RESUMEN

El objeto del presente trabajo es mostrar los    pasos metodológicos y estadísticos que los investigadores biomédicos deben realizar    para evitar una mala estimación de estadígrafos que son necesarios para establecer    hechos y, con ello, evitar inferencias teóricas erradas a partir de hechos empíricamente    mal construidos cuando se comparan dos poblaciones. Se enfatiza en las causas    posibles de este tipo de estimación y se proponen los pasos adecuados para evitar    dichas causas.

Palabras clave: normalidad, homocedasticidad,    observaciones independientes, errores estadísticos, t-student

  En algunos casos, los autores de estudios en    las áreas de la biomedicina, aplican pruebas estadísticas sin considerar las    restricciones que éstas tienen e ignoran el efecto real que las omisiones pueden    generar en los resultados y, como consecuencia, en el enfrentamiento de sus    resultados con la teoría 1. En el caso concreto de comparar dos o más poblaciones    existen cinco restricciones o condiciones que se deben cumplir estrictamente    para realizar este tipo de análisis (1-3): 1) Las observaciones deben ser independientes    entre si; 2) Las observaciones deben hacerse en poblaciones distribuidas normalmente;    3) Estas poblaciones tienen que tener homocedasticidad (igualdad de varianzas)    (o, en casos especiales deben tener una proporción de varianzas conocidas);    4) Las variables correspondientes deben ser cuantitativas continuas y 5) Cuando    existen más de dos poblaciones comparadas, las medias de estas poblaciones normales    y homocedásticas deben ser combinaciones lineales de efectos debidos a las columnas    y a las filas o a ambos. Cuando estas condiciones se satisfacen, entonces se    puede aplicar la prueba "t" o "F", según sea el caso. En la situación en que existe el interés de comparar    dos poblaciones es necesario que se cumplan las condiciones desde la 1 hasta    la 4 para que se pueda aplicar la prueba t-student. (1- 6) Como consecuencia    (asumiendo que las condiciones 1 y 4 se cumplen a priori, lo cual no necesariamente    es así), cada vez que un investigador desee comparar dos grupos de datos mediante    esta prueba, debe necesariamente examinar la normalidad de los mismos en ambos.    Tal normalidad, puede demostrarse empleado algunas de las pruebas que existen    al respecto: Anderson-Larning (7), Kolmogorov-Smirnov (8,9) (con la corrección    de Lilliefore) (9) y Shapiro-Wilk (10), entre otras (11). Una vez comprobada tal normalidad, se debe probar    homocedasticidad. Para este efecto existen pruebas lo suficientemente robustas,    tales como la de Levene (3,11,12) o la de Bartlett (13), entre otras (4). Si    las varianzas resultan iguales es necesario aplicar la prueba t-student específica    para estos casos (1,5,14); en caso contrario, si las varianzas resultan desiguales    se aplica una forma especial de la prueba en análisis, la cual es la t' -student    (t prima) (1,3). Si el supuesto de normalidad no se cumple y, además, no se    considera la presencia o ausencia de homocedasticidad para determinar el tipo    de prueba a aplicar, entonces surge la posibilidad de transformar los datos    (1,3,4,15). El tipo de transformación depende de la estructura y naturaleza    de los valores de la variable, del comportamiento de las varianzas y de las    medias de los valores de las variables (13,15). La transformación de los datos    busca normalizar la distribución no normal de los datos originales o igualdad    de varianzas entre los "tratamientos" o ambos al mismo tiempo. Luego    de transformar los datos, se aplican algunas de las pruebas antes descritas    y, se verifica el supuesto y la homocedasticidad bajo las condiciones de datos    transformados. Si se cumple la normalidad, se puede aplicar la prueba t correspondiente,    en concordancia con la relación entre varianzas observadas (1). Bajo las circunstancias de que la normalidad    no se cumplen y no se considera la presencia o ausencia de homocedasticidad,    aún después de trasformar los datos adecuadamente (1,2,4,15) y el investigador    insiste en aplicar la prueba t "tradicional" (a datos originales o    transformados), se pierde Potencia (1-13) en la aplicación de la prueba y no    se puede controlar la probabilidad del error de Tipo I (a) (2), lo que puede    conducir a encontrar significaciones estadísticas donde no existen o viceversa.    Esto sólo tiene una traducción posible: los hechos que emanan del resumen estadístico    no tienen validez ninguna y, por tanto, toda inferencia teórica sobre su base    podría contener errores. Se han reunido pruebas empíricas demostrando que las    desviaciones ligeras de los supuestos intrínsecos de las pruebas paramétricas    no pueden tener efectos radicales en la cifra de probabilidad obtenida (2,5,6)    o que el uso de un diseño aleatorizado permite probar hipótesis sin necesidad    de suponer la forma de la distribución (5,6), pero el problema que surge es    el hecho de que aún no se sabe que se entiende por "ligera desviación"    y, en el campo de la biomedicina, es muy frecuente que los sujetos no se asignen    al azar a los distintos tratamientos (grupos que se comparan: sanos y enfermos)    1. Como consecuencia, ante esta indefinición, es preferible adoptar un estilo    "ortodoxo" en el cual se manifieste la estricta demostración del cumplimiento    de cada supuesto antes señalado antes de usar la prueba adecuada para cada caso    (1,3). Si la normalidad no se cumple, no queda otra    alternativa que emplear las pruebas no paramétricas. Las alternativas no paramétricas    de la prueba de t-student más empleadas son las pruebas U de Mann-Whitney y    la prueba Z de Kolmogorov-Smirnov (1,3,13,15,16), entre otras (1,3,13,15-17),    las cuales han demostrado su eficacia y confiabilidad como alternativa (1,2,17). De lo antes planteado, surge el concepto de Potencia-    Eficiencia de una prueba, el cual se refiere al incremento del tamaño de muestra    necesario para hacer una prueba, por ejemplo, B tan poderosa como otra prueba    que llamaremos A, donde esta última es la más poderosa conocida (2). Las pruebas    paramétricas (t-student entre ellas) tienen mayor potencia-eficiencia que las    no paramétricas (2,17); por tal razón los investigadores deben preferir el uso    de pruebas paramétricas. Pero, ante la imposibilidad de su uso (por las razones    antes explicadas), se debe procurar las no paramétricas, tratando de incrementar    al máximo el tamaño de muestra (n) posible en ambos grupos de tal forma que    tal incremento permita, a su vez, aumentar la potencia perdida por la imposibilidad    de emplear pruebas paramétricas (2,17).   BIBLIOGRAFÍA 1. Díaz VR Metodología de la Investigación Científica    y Bioestadística para Profesionales y Estudiantes de Ciencias de la Salud. Primera    Edición. RiL Editores. Santiago. 2009. (en prensa).        [ Links ]2. Siegel S. Diseño experimental no paramétrico.    Editorial Científico-Técnica. La Habana. Cuba. 1972.        [ Links ]3. Ostle B. Estadística Aplicada. Editorial LIMUSA.    México. 1981.        [ Links ]4. Kuehl RO. Diseño de Experimentos. 2da. Edición.    Thomson Editores SA. México. 2001.        [ Links ]5. Montgomery DC Diseño y Análisis de Experimentos.    Primera Edición. Grupo Editorial Iberoamérica. México. 1991.        [ Links ]6. Box GE, Hunter WG, Hunter JS. Statistics for    Experimenters. 1st. ed. Wiley. NY. 1978.        [ Links ]7. Arnold SF. Mathematical Statistics. Prentice-Hall.    1990.        [ Links ]8. D'Agostino RB, Stephens MA. Goodness-of-Fit    Techniques. R.B. D'Agostino and M.A. Stephens, Eds. Edit. Marcel Dekke, Inc.    New York. 1986.        [ Links ]9. Lilliefore HW. "On the Kolmogorov-Smirnov    Test for Normality with Mean and Variance Unknown," J Am Stat Assoc 1967;    62: 399-402.        [ Links ]10. Shapiro S S, Wilk MB. An Analysis of Variance    Test for Normality (Complete Samples). Biometrika; 52: 591-598. 1965.        [ Links ]11. Hair JF, Anderson RE, Tatham RL, Black WC.    Analisis multivariante. Editorial Prentice-Hall. Madrid. 2001.        [ Links ]12. Levene H. Contributions to Probability and    Statistics. Stanford University Press. 1960.        [ Links ]13. Lerch G Diseño Experimental para las Ciencias    Agrícolas y Biológicas. Editorial Científico-Técnica. La Habana. 1977.        [ Links ]14. Hicks CR. Fundamental Concepts in the Design    of Experiments. Third Edition. CBC College Publishing. 1982.        [ Links ]15. Dixon WJ, Massey FJ. Introducción al análisis    estadístico. Instituto Cubano del Libro. La Habana. 1974.        [ Links ]16. Visauta B. Análisis estadístico con SPSS.    McGraw-Hill. Madrid. 1999.        [ Links ]17. Gibbons J.D. Nonparametric Methods for Quantitative    Analysis. Holt, Rhinehart, and Winston Edit. New. York. 1976.        [ Links ]  Este trabajo fue recibido el 21 de Mayo de 2009    y aceptado para ser publicado el 12 de Noviembre de 2009. Dirigir    la correspondencia a: 

Profesor Víctor Patricio Díaz Narváez        Facultad de Odontología Universidad Finis Terrae        Pedro de Valdivia 1509 Santiago. Chile. E-mail: vpdiaz@tie.cl 

En algunos casos, los autores de estudios en    las áreas de la biomedicina, aplican pruebas estadísticas sin considerar las    restricciones que éstas tienen e ignoran el efecto real que las omisiones pueden    generar en los resultados y, como consecuencia, en el enfrentamiento de sus    resultados con la teoría 1. En el caso concreto de comparar dos o más poblaciones    existen cinco restricciones o condiciones que se deben cumplir estrictamente    para realizar este tipo de análisis (1-3): 1) Las observaciones deben ser independientes    entre si; 2) Las observaciones deben hacerse en poblaciones distribuidas normalmente;    3) Estas poblaciones tienen que tener homocedasticidad (igualdad de varianzas)    (o, en casos especiales deben tener una proporción de varianzas conocidas);    4) Las variables correspondientes deben ser cuantitativas continuas y 5) Cuando    existen más de dos poblaciones comparadas, las medias de estas poblaciones normales    y homocedásticas deben ser combinaciones lineales de efectos debidos a las columnas    y a las filas o a ambos. Cuando estas condiciones se satisfacen, entonces se    puede aplicar la prueba "t" o "F", según sea el caso.

En la situación en que existe el interés de comparar    dos poblaciones es necesario que se cumplan las condiciones desde la 1 hasta    la 4 para que se pueda aplicar la prueba t-student. (1- 6) Como consecuencia    (asumiendo que las condiciones 1 y 4 se cumplen a priori, lo cual no necesariamente    es así), cada vez que un investigador desee comparar dos grupos de datos mediante    esta prueba, debe necesariamente examinar la normalidad de los mismos en ambos.    Tal normalidad, puede demostrarse empleado algunas de las pruebas que existen    al respecto: Anderson-Larning (7), Kolmogorov-Smirnov (8,9) (con la corrección    de Lilliefore) (9) y Shapiro-Wilk (10), entre otras (11).

Una vez comprobada tal normalidad, se debe probar    homocedasticidad. Para este efecto existen pruebas lo suficientemente robustas,    tales como la de Levene (3,11,12) o la de Bartlett (13), entre otras (4). Si    las varianzas resultan iguales es necesario aplicar la prueba t-student específica    para estos casos (1,5,14); en caso contrario, si las varianzas resultan desiguales    se aplica una forma especial de la prueba en análisis, la cual es la t' -student    (t prima) (1,3). Si el supuesto de normalidad no se cumple y, además, no se    considera la presencia o ausencia de homocedasticidad para determinar el tipo    de prueba a aplicar, entonces surge la posibilidad de transformar los datos    (1,3,4,15). El tipo de transformación depende de la estructura y naturaleza    de los valores de la variable, del comportamiento de las varianzas y de las    medias de los valores de las variables (13,15). La transformación de los datos    busca normalizar la distribución no normal de los datos originales o igualdad    de varianzas entre los "tratamientos" o ambos al mismo tiempo. Luego    de transformar los datos, se aplican algunas de las pruebas antes descritas    y, se verifica el supuesto y la homocedasticidad bajo las condiciones de datos    transformados. Si se cumple la normalidad, se puede aplicar la prueba t correspondiente,    en concordancia con la relación entre varianzas observadas (1).

Bajo las circunstancias de que la normalidad    no se cumplen y no se considera la presencia o ausencia de homocedasticidad,    aún después de trasformar los datos adecuadamente (1,2,4,15) y el investigador    insiste en aplicar la prueba t "tradicional" (a datos originales o    transformados), se pierde Potencia (1-13) en la aplicación de la prueba y no    se puede controlar la probabilidad del error de Tipo I (a) (2), lo que puede    conducir a encontrar significaciones estadísticas donde no existen o viceversa.    Esto sólo tiene una traducción posible: los hechos que emanan del resumen estadístico    no tienen validez ninguna y, por tanto, toda inferencia teórica sobre su base    podría contener errores. Se han reunido pruebas empíricas demostrando que las    desviaciones ligeras de los supuestos intrínsecos de las pruebas paramétricas    no pueden tener efectos radicales en la cifra de probabilidad obtenida (2,5,6)    o que el uso de un diseño aleatorizado permite probar hipótesis sin necesidad    de suponer la forma de la distribución (5,6), pero el problema que surge es    el hecho de que aún no se sabe que se entiende por "ligera desviación"    y, en el campo de la biomedicina, es muy frecuente que los sujetos no se asignen    al azar a los distintos tratamientos (grupos que se comparan: sanos y enfermos)    1. Como consecuencia, ante esta indefinición, es preferible adoptar un estilo    "ortodoxo" en el cual se manifieste la estricta demostración del cumplimiento    de cada supuesto antes señalado antes de usar la prueba adecuada para cada caso    (1,3).

Si la normalidad no se cumple, no queda otra    alternativa que emplear las pruebas no paramétricas. Las alternativas no paramétricas    de la prueba de t-student más empleadas son las pruebas U de Mann-Whitney y    la prueba Z de Kolmogorov-Smirnov (1,3,13,15,16), entre otras (1,3,13,15-17),    las cuales han demostrado su eficacia y confiabilidad como alternativa (1,2,17).

De lo antes planteado, surge el concepto de Potencia-    Eficiencia de una prueba, el cual se refiere al incremento del tamaño de muestra    necesario para hacer una prueba, por ejemplo, B tan poderosa como otra prueba    que llamaremos A, donde esta última es la más poderosa conocida (2). Las pruebas    paramétricas (t-student entre ellas) tienen mayor potencia-eficiencia que las    no paramétricas (2,17); por tal razón los investigadores deben preferir el uso    de pruebas paramétricas. Pero, ante la imposibilidad de su uso (por las razones    antes explicadas), se debe procurar las no paramétricas, tratando de incrementar    al máximo el tamaño de muestra (n) posible en ambos grupos de tal forma que    tal incremento permita, a su vez, aumentar la potencia perdida por la imposibilidad    de emplear pruebas paramétricas (2,17).